{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic comment detection using SVM and different vectorization features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/krise/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/krise/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/krise/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import preprocessing\n",
    "import nltk\n",
    "from nltk import ngrams\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import editdistance\n",
    "from spellchecker import SpellChecker\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "#List of profane words \n",
    "profane_list = list(pd.read_csv(\"data/profane_list2.csv\")['name'])\n",
    "most_tox_features_list = list(pd.read_csv(\"data/top_toxic_featurenames_long.csv\")['word'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Featurizer and training & evaluation functions based on https://github.com/bmeaut/python_nlp_2018_spring/blob/master/course_material/14_Semantics_II/14_Semantics_2_lab.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom featurizer calss\n",
    "#Can either be used as a standalone featurizer or build upon the dictionary of an existing featurizer such that\n",
    "#the output of this featurizer and the foreign featurizer can be concatenated and this featurizers dictionary\n",
    "#can be used as the dictionary for the result.\n",
    "\n",
    "class Featurizer():    \n",
    "    sa = SentimentIntensityAnalyzer() #vader sentiment analyzer for sentence-sentiment feature\n",
    "    feature_functions = [] #for holding function names that the Featurizer shall apply\n",
    "    \n",
    "    #potential feature functions:\n",
    "    @staticmethod\n",
    "    def number_of_profanities(text):\n",
    "        n = 0\n",
    "        words_tokenized = word_tokenize(text)\n",
    "        for word in words_tokenized:\n",
    "            if (word in profane_list):\n",
    "                n += 1\n",
    "        yield (\"number of profanities\", n / len(words_tokenized))  \n",
    "        \n",
    "    @staticmethod\n",
    "    def pos_tags(text):\n",
    "        word_tag_tuples = nltk.pos_tag(word_tokenize(text))\n",
    "        tag_count_dict = {}\n",
    "        for word_tag_tuple in word_tag_tuples:\n",
    "            if(word_tag_tuple[1] in tag_count_dict.keys()):\n",
    "                tag_count_dict[word_tag_tuple[1]] += 1\n",
    "            else:\n",
    "                tag_count_dict[word_tag_tuple[1]] = 1\n",
    "\n",
    "        for tag in tag_count_dict:\n",
    "            yield (tag, tag_count_dict[tag] / len(word_tag_tuples))\n",
    "\n",
    "    @staticmethod\n",
    "    def vader_sentiment(text):\n",
    "        sentiments = Featurizer.sa.polarity_scores(text)\n",
    "        for key in sentiments:\n",
    "            yield(\"vader \" + key, sentiments[key])\n",
    "            \n",
    "    @staticmethod\n",
    "    def comment_length(text):\n",
    "        yield (\"text length\", len(text))\n",
    "            \n",
    "    @staticmethod\n",
    "    def percentage_uppercase(text):\n",
    "        yield (\"% uppercase\", sum(1 for c in text if c.isupper()) /len(text))       \n",
    "    \n",
    "    @staticmethod\n",
    "    def pos_ngrams(text):\n",
    "        n = 2\n",
    "        tokens = word_tokenize(text)\n",
    "        tag_count_dict = {}\n",
    "        \n",
    "        l = len(tokens)\n",
    "        word_tag_tuples = nltk.pos_tag(tokens)\n",
    "        for x in range(0, l - n + 1):\n",
    "            pos_ngram = \"\"\n",
    "            for i in range(0, n):\n",
    "                pos_ngram += word_tag_tuples[x + i][1] + \" \"\n",
    "            if(pos_ngram in tag_count_dict.keys()):\n",
    "                tag_count_dict[pos_ngram] += 1\n",
    "            else:\n",
    "                tag_count_dict[pos_ngram] = 1\n",
    "\n",
    "        for tag in tag_count_dict:\n",
    "            yield (tag, tag_count_dict[tag] / (len(word_tag_tuples) / 2))\n",
    "        \n",
    "    #Either start completely new feature/id dictionary if only features of this custom featurizer will be used\n",
    "    #or base dictionary on that of a different featurizer so they can be used together (e.g sklearns TFIDF vectorizer)\n",
    "    def __init__(self, foreign_features = None):\n",
    "        if (foreign_features == None): #Will create standalone dictionaries\n",
    "            self.features = {}\n",
    "            self.features_by_id = {}\n",
    "            self.next_feature_id = 0\n",
    "            self.max_foreign_feature = 0\n",
    "        else: #Some other vectorizer will be used in addition to this one\n",
    "            self.features = foreign_features\n",
    "            self.features_by_id = {v: k for k, v in foreign_features.items()}\n",
    "            self.next_feature_id = max(foreign_features.values()) + 1\n",
    "            self.max_foreign_feature = self.next_feature_id\n",
    "\n",
    "    def to_sparse(self, events):\n",
    "        \"\"\"convert sets of ints to a scipy.sparse.csr_matrix\"\"\"\n",
    "        data, row_ind, col_ind = [], [], []\n",
    "        for event_index, event in enumerate(events):\n",
    "            for feature, value in event:\n",
    "                if (value != None):\n",
    "                    data.append(value)\n",
    "                else:\n",
    "                    data.append(1)\n",
    "                    \n",
    "                row_ind.append(event_index)\n",
    "                #foreign features will be 0 if only this featurizer is used\n",
    "                col_ind.append(feature - self.max_foreign_feature) \n",
    "                \n",
    "        n_features = len(self.features.keys()) - self.max_foreign_feature\n",
    "        n_events = len(events)\n",
    "        matrix = scipy.sparse.csr_matrix(\n",
    "            (data, (row_ind, col_ind)), shape=(n_events, n_features))\n",
    "        return matrix\n",
    "\n",
    "    def featurize(self, dataset, allow_new_features=False, verbose = False):\n",
    "        events, labels = [], []\n",
    "        n_events = len(dataset)\n",
    "        for c, (text, label) in enumerate(dataset):\n",
    "            if (verbose):\n",
    "                if c % 10000 == 0:\n",
    "                    print(\"{0:.0%}...\".format(c/n_events), end='')\n",
    "            labels.append(label)\n",
    "            events.append(set())\n",
    "            for function_name in Featurizer.feature_functions:\n",
    "                function = getattr(Featurizer, function_name)\n",
    "                for feature, value in function(text):\n",
    "                    if feature not in self.features:\n",
    "                        if not allow_new_features:\n",
    "                            continue\n",
    "                        self.features[feature] = self.next_feature_id\n",
    "                        self.features_by_id[self.next_feature_id] = feature\n",
    "                        self.next_feature_id += 1\n",
    "                    feat_id = self.features[feature]\n",
    "                    events[-1].add((feat_id, value))\n",
    "                    \n",
    "        events_sparse = self.to_sparse(events)\n",
    "        labels_array = np.array(labels)\n",
    "        print('done!')\n",
    "        return events_sparse, labels_array\n",
    "\n",
    "    def get_feature_names(self):\n",
    "        return list([k for k, v in sorted(self.features.items(), key=lambda item: item[1])])\n",
    "    \n",
    "    def get_featurname_to_id_dict(self):\n",
    "        return self.features\n",
    "        \n",
    "    def get_id_to_featurname_dict(self):\n",
    "        return self.features_by_id\n",
    "        \n",
    "    #merge two feature matrices\n",
    "    def merge_feature_matrices(self, foreign_matrix, inherent_matrix):\n",
    "        return sp.hstack([foreign_matrix, inherent_matrix])\n",
    "    \n",
    "    #print feature values and names \n",
    "    def print_sample_with_feature_names(self, feature_matrix, sample_id):\n",
    "        sample = feature_matrix.getrow(sample_id)\n",
    "        nonzero_idxs = sample.nonzero()[1]\n",
    "        for idx in nonzero_idxs:\n",
    "            print(self.features_by_id[idx].rjust(30, ' ') , \":\" , sample.getcol(idx).toarray()[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting most important features for SVM in a plot(works only for linear kernel)\n",
    "def plot_coefficients(classifier, feature_names, top_features=20):\n",
    "    #feature_names*=3\n",
    "    coef = classifier.coef_.ravel()\n",
    "    top_positive_coefficients = np.argsort(-coef)[:top_features]\n",
    "    top_negative_coefficients = np.argsort(-coef)[-top_features:]\n",
    "    top_coefficients = np.hstack([top_positive_coefficients, top_negative_coefficients])\n",
    "    # create plot\n",
    "    plt.figure(figsize=(3, 10))\n",
    "    colors = ['green' if c < 0 else 'red' for c in coef[top_coefficients]]\n",
    "    plt.barh(np.arange(2 * top_features), coef[top_coefficients], color=colors)\n",
    "    feature_names = np.array(feature_names)\n",
    "    plt.yticks(np.arange(0,2 * top_features), feature_names[top_coefficients], ha='right')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best results so far for comparing\n",
    "base = {\"1 precision\": 0.66, \"1 recall\" : 0.58, \"1 f-score\" :0.61, \"0 precision\": 0.96, \\\n",
    "        \"0 recall\" : 0.97, \"0 f-score\" :0.97, \"acc\" : 0.9422, \"Av.rec\": 0.5169, \"auc\": 0.8101}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print results and save some examples of correctly and incorrectly classified comments to disk\n",
    "def evaluate(predictions, dev_labels, valid_df, model, featurizer, plot):\n",
    "    stats_by_label = defaultdict(lambda: defaultdict(int))\n",
    "    if (isinstance(predictions, np.ndarray)):\n",
    "        predictions = predictions.tolist()\n",
    "    for i, gold in enumerate(dev_labels):\n",
    "        auto = predictions[i]\n",
    "        # print(auto, gold)\n",
    "        if auto == gold:\n",
    "            stats_by_label[auto]['tp'] += 1\n",
    "        else:\n",
    "            stats_by_label[auto]['fp'] += 1\n",
    "            stats_by_label[gold]['fn'] += 1\n",
    "\n",
    "    print(\"{:>8} {:>8}  {:>8}    {:>8}         {:>8}             {:>8}\".format(\n",
    "        'label', 'n_true', 'n_tagged', 'precision', 'recall', 'F-score'))\n",
    "    for label, stats in stats_by_label.items():\n",
    "        all_tagged = stats['tp'] + stats['fp']\n",
    "        stats['prec'] = stats['tp'] / all_tagged if all_tagged else 0\n",
    "        all_true = stats['tp'] + stats['fn']\n",
    "        stats['rec'] = stats['tp'] / all_true if all_true else 0\n",
    "        stats['f'] = (2 / ((1/stats['prec']) + (1/stats['rec']))\n",
    "                      if stats['prec'] > 0 and stats['rec'] > 0 else 0)\n",
    "\n",
    "        print(\"{:>8} {:>8} {:>8} {:>8.2f} / {:<8.2f} {:>8.2f} / {:<8.2f} {:>8.2f} / {:<8.2f}\".format(\n",
    "            label, all_true, all_tagged, stats['prec'], base[str(label) + \" precision\"], stats['rec'], \n",
    "            base[str(label) + \" recall\"], stats['f'], base[str(label) + \" f-score\"]))\n",
    "\n",
    "    accuracy = (\n",
    "        sum([stats_by_label[label]['tp'] for label in stats_by_label]) /\n",
    "        len(predictions)) if predictions else 0\n",
    "\n",
    "    av_rec = sum([stats['rec'] for stats in stats_by_label.values()]) / 3\n",
    "    f_pn = (stats_by_label['positive']['f'] +\n",
    "            stats_by_label['negative']['f']) / 2\n",
    "\n",
    "    print()\n",
    "    print(\"{:>10} {:>.4f} / {:<.4f}\".format('Acc:', accuracy, base[\"acc\"]))\n",
    "    print(\"{:>10} {:>.4f} / {:<.4f}\".format('Av.rec:', av_rec, base[\"Av.rec\"]))\n",
    "    print(\"{:>10} {:>.4f} / {:<.4f}\".format('AUC :', roc_auc_score(predictions, dev_labels), base[\"auc\"]))\n",
    "    print(\"-----------------------------\")\n",
    "    \n",
    "    incorrectly_classified_msk = [ x != y for (x,y) in zip(predictions, list(valid_df['target']))]\n",
    "    correctly_classified_msk = [not x for x in incorrectly_classified_msk]\n",
    "    incorrectly_classified = valid_df[incorrectly_classified_msk]\n",
    "    correctly_classified = valid_df[correctly_classified_msk]\n",
    "    \n",
    "    incorrectly_classified_ambig = incorrectly_classified.loc[(incorrectly_classified['toxicity'] > 0.4)\\\n",
    "                                                              & (incorrectly_classified['toxicity'] < 0.6)] \n",
    "    print(\"From\", len(incorrectly_classified), \"incorrectly classified,\", len(incorrectly_classified_ambig),\\\n",
    "          \"are ambiguous\", \"(\", len(incorrectly_classified_ambig) / len(incorrectly_classified) *100, \"%)\")\n",
    "    \n",
    "    incorrectly_classified.loc[(incorrectly_classified['toxicity'] <= 0.4)\\\n",
    "                                | (incorrectly_classified['toxicity'] >= 0.6)].head(1000).to_csv(\"examples/incorrect.csv\")\n",
    "    correctly_classified.loc[(correctly_classified['toxicity'] <= 0.4)\\\n",
    "                                | (incorrectly_classified['toxicity'] >= 0.6)].head(1000).to_csv(\"examples/correct.csv\")\n",
    "    print(\"saved (non-ambiguous) examples for correctly and incorrectly classified comments to /examples\" )\n",
    "    \n",
    "    if (plot):\n",
    "        plot_coefficients(model, featurizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['comment_text', 'toxicity','target']\n",
    "\n",
    "train_df = pd.read_csv(\"data/pre_processed/train_lemma_nopunct_cleaned_sentencized.csv\", usecols = fields)\n",
    "#train_df = pd.read_csv(\"experimental/train_negations_fliped.csv\", usecols = fields)\n",
    "train_df = train_df[:int(len(train_df) * 1/4)]\n",
    "train_df.dropna(inplace = True)\n",
    "valid_df = pd.read_csv(\"data/merged_with_txt.csv\")\n",
    "#valid_df = pd.read_csv(\"data/pre_processed/valid_lemma_nopunct_cleaned_sentencized.csv\", usecols = fields)\n",
    "#valid_df = pd.read_csv(\"experimental/valid_negations_fliped.csv\", usecols = fields)\n",
    "valid_df.dropna(inplace = True)\n",
    "test_df = pd.read_csv(\"data/pre_processed/test_lemma_nopunct_cleaned_sentencized.csv\", usecols = fields)\n",
    "test_df.dropna(inplace = True)\n",
    "\n",
    "train = list(zip(list(train_df['comment_text']), list(train_df['target'])))\n",
    "valid = list(zip(list(valid_df['comment_text']), list(valid_df['target'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(train_events, train_labels, valid_events, valid_labels, valid_df, featurizer, plot = False):\n",
    "    print('training...')\n",
    "    start = time.time()\n",
    "    model = svm.LinearSVC(max_iter = 10000)\n",
    "    model.fit(train_events, train_labels)\n",
    "    end = time.time()\n",
    "    print(\"Training took:\", int((end-start)), \"sec\")\n",
    "\n",
    "    start = time.time()\n",
    "    predicted_labels = model.predict(valid_events)\n",
    "    end = time.time()\n",
    "    print(\"Predicting took:\", int((end-start)), \"sec\")\n",
    "\n",
    "    evaluate(predicted_labels, valid_labels, valid_df, model, featurizer, plot)\n",
    "    return featurizer, train_events, train_labels, valid_events, valid_labels, predicted_labels, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_train_evaluate(train, valid, valid_df, verbose = False, plot = False):\n",
    "    print('featurizing train...')\n",
    "    featurizer = Featurizer()\n",
    "    start = time.time()\n",
    "    train_events, train_labels = featurizer.featurize(train, allow_new_features=True, verbose = verbose)\n",
    "    print('featurizing valid...')\n",
    "    valid_events, valid_labels = featurizer.featurize(valid, allow_new_features=False, verbose = verbose)\n",
    "    end = time.time()\n",
    "    print(\"Vectorizing took:\", int((end-start)), \"sec\")\n",
    "    \n",
    "    return train_and_evaluate(train_events, train_labels, valid_events, valid_labels, valid_df, featurizer, plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFIDF scores for word monograms and bigrams as a baseline for adding additional features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Training took: 5 sec\n",
      "Predicting took: 0 sec\n",
      "   label   n_true  n_tagged    precision           recall              F-score\n",
      "       1    28788    25364     0.66 / 0.66         0.58 / 0.58         0.61 / 0.61    \n",
      "       0   332306   335730     0.96 / 0.96         0.97 / 0.97         0.97 / 0.97    \n",
      "\n",
      "      Acc: 0.9422 / 0.9422\n",
      "   Av.rec: 0.5172 / 0.5169\n",
      "     AUC : 0.8098 / 0.8101\n",
      "-----------------------------\n",
      "From 20880 incorrectly classified, 6398 are ambiguous ( 30.64176245210728 %)\n",
      "saved (non-ambiguous) examples for correctly and incorrectly classified comments to /examples\n"
     ]
    }
   ],
   "source": [
    "#Testing showed that there seems to be no improvement when using more than bigrams\n",
    "#tfidf_vectorizer_chars = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (1,5), min_df = 10)\n",
    "tfidf_vectorizer_words = TfidfVectorizer(ngram_range = (1,2)) \n",
    "#chars_dict = tfidf_vectorizer_chars.vocabulary_.copy()\n",
    "#words_dict = tfidf_vectorizer_words.vocabulary_.copy()\n",
    "\n",
    "#max_id_chars = chars_dict[max(chars_dict, key=chars_dict.get)]\n",
    "#words_dict = {k: (v + max_id_chars + 1) for k, v words_dict.items()}\n",
    "#char_word_dict = {**chars_dict, words_dict}\n",
    "\n",
    "#sp.hstack([tfidf_vectorizer_chars, tfidf_vectorizer_words])\n",
    "\n",
    "#tfidf_train_chars = tfidf_vectorizer_chars.fit_transform(train_df['comment_text'])\n",
    "tfidf_train_words = tfidf_vectorizer_words.fit_transform(train_df['comment_text'])\n",
    "target_train = list(train_df[\"target\"])\n",
    "\n",
    "#tfidf_valid_chars = tfidf_vectorizer_chars.transform(valid_df['comment_text'])\n",
    "tfidf_valid_words = tfidf_vectorizer_words.transform(valid_df['comment_text'])\n",
    "target_valid = list(valid_df[\"target\"])\n",
    "\n",
    "#tfidf_train = sp.hstack([tfidf_train_chars, tfidf_train_words])\n",
    "#tfidf_valid = sp.hstack([tfidf_valid_chars, tfidf_valid_words])\n",
    "\n",
    "res = train_and_evaluate(tfidf_train_words, target_train, tfidf_valid_words, target_valid, valid_df, tfidf_vectorizer_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding additional features on top of the TFIDF values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0%...3%...6%...8%...11%...14%...17%...19%...22%...25%...28%...30%...33%...36%...39%...42%...44%...47%...50%...53%...55%...58%...61%...64%...66%...69%...72%...75%...78%...80%...83%...86%...89%...91%...94%...97%...100%...done!\n",
      "0%...3%...6%...8%...11%...14%...17%...19%...22%...25%...28%...30%...33%...36%...39%...42%...44%...47%...50%...53%...55%...58%...61%...64%...66%...69%...72%...75%...78%...80%...83%...86%...89%...91%...94%...97%...100%...done!\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'tfidf_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3923663a7c11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#combine outputs of tfidf and custom featurizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_tfidf_custom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_featurizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_feature_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mvalid_tfidf_custom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_featurizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_feature_matrices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_events\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tfidf_train' is not defined"
     ]
    }
   ],
   "source": [
    "#set additional features\n",
    "Featurizer.feature_functions = ['pos_tags']\n",
    "\n",
    "#create featurizer who's dictionary is based on the tfidf-vectorizers dictionary\n",
    "custom_featurizer = Featurizer(foreign_features = tfidf_vectorizer_words.vocabulary_.copy())\n",
    "train_events, train_labels = custom_featurizer.featurize(train, allow_new_features=True, verbose = True)\n",
    "valid_events, valid_labels = custom_featurizer.featurize(valid, allow_new_features=False, verbose = True)\n",
    "\n",
    "#combine outputs of tfidf and custom featurizer\n",
    "train_tfidf_custom = custom_featurizer.merge_feature_matrices(tfidf_train, train_events)\n",
    "valid_tfidf_custom = custom_featurizer.merge_feature_matrices(tfidf_valid, valid_events)\n",
    "\n",
    "res = train_and_evaluate(train_tfidf_custom, train_labels, valid_tfidf_custom, valid_labels, valid_df, custom_featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing featurized version of a comment to check if everything went right \n",
    "custom_featurizer.print_sample_with_feature_names(valid_tfidf_custom, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper methods for performing spell-checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "def canBeEqual(a, b):\n",
    "    l = len(a)\n",
    "    if l != len(b):\n",
    "        return False\n",
    "    for i in range(0, l - 1):\n",
    "        if (a[:i] + a[i + 1] + a[i] + (a[i + 2:] if (i < l) else \"\") == b):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def spellfix_toxic_words(string, freq_dict):\n",
    "    global i\n",
    "    #for token in word_tokenize(string):\n",
    "    for token in string.split():\n",
    "        if (len(token) > 3 and freq_dict[token] < 5):\n",
    "            for tox_word in most_tox_features_list:\n",
    "                ed = editdistance.eval(token.lower(), tox_word.lower())\n",
    "                if ((ed == 1 or ed ==2) and '*' in token):\n",
    "                    #print(\"fixing\", token, tox_word)\n",
    "                    #i +=1\n",
    "                    return string.replace(token, tox_word)\n",
    "                elif (ed == 2 and canBeEqual(token.lower(), tox_word.lower())):\n",
    "                    #print(\"fixing\", token, tox_word)\n",
    "                    #i += 1\n",
    "                    return string.replace(token, tox_word) \n",
    "                elif (ed == 1 and len(spell.unknown([token.lower()])) > 0):\n",
    "                    #print(\"fixing\", token, tox_word)\n",
    "                    #i += 1\n",
    "                    return string.replace(token, tox_word)\n",
    "                elif (token.count('*') >= 2 and token.lower().replace('*', '') == tox_word.lower()):\n",
    "                    #print(\"fixing\", token, tox_word)\n",
    "                    #i += 1\n",
    "                    return string.replace(token, tox_word)              \n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering the above trained model as the baseline, this method is used for comparing it against a different model (be it a model with different features/parameters or different preprocessing). A comparison of the 2 models is then printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Training took: 3 sec\n",
      "Predicting took: 0 sec\n",
      "   label   n_true  n_tagged    precision           recall              F-score\n",
      "       1    28788    24109     0.66 / 0.66         0.55 / 0.58         0.60 / 0.61    \n",
      "       0   332306   336985     0.96 / 0.96         0.98 / 0.97         0.97 / 0.97    \n",
      "\n",
      "      Acc: 0.9411 / 0.9422\n",
      "   Av.rec: 0.5081 / 0.5169\n",
      "     AUC : 0.8086 / 0.8101\n",
      "-----------------------------\n",
      "From 21277 incorrectly classified, 6591 are ambiguous ( 30.977111434882737 %)\n",
      "saved (non-ambiguous) examples for correctly and incorrectly classified comments to /examples\n",
      "\n",
      "--------------------------------------------------\n",
      "                  old  |  new\n",
      "Precision 1    = 0.68  |  0.66\n",
      "Precision 0    = 0.96  |  0.96\n",
      "Recall 1       = 0.55  |  0.55\n",
      "Recall 0       = 0.98  |  0.98\n",
      "F-score 1      = 0.61  |  0.60\n",
      "F-score 0      = 0.97  |  0.97\n",
      "\n",
      "Total          : fixed = 2071 (0.574%)  |  falsified = 2908 (0.805%)\n",
      "False positives : fixed =  914 (0.253%)  |  introduced = 1888 (0.523%)\n",
      "False negatives : fixed = 1157 (0.320%)  |  introduced = 1020 (0.282%)\n"
     ]
    }
   ],
   "source": [
    "def compare_different_approaches(res, train_df, valid_df):\n",
    "    fields = ['comment_text', 'toxicity','target']\n",
    "    tfidf_vectorizer = TfidfVectorizer(ngram_range = (1,2))\n",
    "\n",
    "    tfidf_train = tfidf_vectorizer.fit_transform(train_df['comment_text'])\n",
    "    target_train = list(train_df[\"target\"])\n",
    "    tfidf_valid = tfidf_vectorizer.transform(valid_df['comment_text'])\n",
    "    valid_train = list(valid_df[\"target\"])\n",
    "\n",
    "    res1 = train_and_evaluate(tfidf_train, target_train, tfidf_valid, valid_train, valid_df, tfidf_vectorizer)\n",
    "\n",
    "    featurizer, train_events, train_labels, valid_events, valid_labels, predicted_labels, model = res\n",
    "    featurizer1, train_events1, train_labels1, valid_events1, valid_labels1, predicted_labels1, model1 = res1\n",
    "\n",
    "    difference_msk = [ x != y for (x,y) in zip(predicted_labels, predicted_labels1)]\n",
    "    differently_classified = pd.DataFrame(valid_df.loc[difference_msk])\n",
    "\n",
    "    differently_classified[\"initial\"] = predicted_labels[difference_msk]\n",
    "    differently_classified[\"with_different_preproc\"] = predicted_labels1[difference_msk]\n",
    "    differently_classified.to_csv(\"examples/differently_classified.csv\")\n",
    "\n",
    "    total_corrected = 0\n",
    "    false_positives_introduced = 0\n",
    "    false_positives_fixed = 0\n",
    "    false_negatives_introduced = 0\n",
    "    false_negatives_fixed = 0\n",
    "    total_falsified = 0\n",
    "\n",
    "    for index, row in differently_classified.iterrows():\n",
    "        #print(row['comment_text'])\n",
    "        if ((row[\"target\"] == row[\"initial\"]) and (row[\"target\"] != row[\"with_different_preproc\"])):\n",
    "                total_falsified += 1\n",
    "                if (row[\"target\"] == 0):\n",
    "                    false_positives_introduced += 1\n",
    "                else:\n",
    "                    false_negatives_introduced += 1\n",
    "        if ((row[\"target\"] != row[\"initial\"]) and (row[\"target\"] == row[\"with_different_preproc\"])):\n",
    "                total_corrected += 1\n",
    "                if (row[\"target\"] == 0):\n",
    "                    false_negatives_fixed += 1\n",
    "                else:\n",
    "                    false_positives_fixed += 1\n",
    "\n",
    "    valid_len = len(valid_df)\n",
    "    \n",
    "    scores_old = precision_recall_fscore_support(valid_labels, predicted_labels)\n",
    "    scores_new = precision_recall_fscore_support(valid_labels1, predicted_labels1)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"-\" * 50)\n",
    "    print(\"{:>21s}  |  {:3s}\".format(\"old\", \"new\"))\n",
    "    print(\"{:15s}= {:2.2f}  |  {:2.2f}\".format(\"Precision 1\", scores_old[0][1], scores_new[0][1]))\n",
    "    print(\"{:15s}= {:2.2f}  |  {:2.2f}\".format(\"Precision 0\", scores_old[0][0], scores_new[0][0]))\n",
    "    print(\"{:15s}= {:2.2f}  |  {:2.2f}\".format(\"Recall 1\", scores_old[1][1], scores_new[1][1]))\n",
    "    print(\"{:15s}= {:2.2f}  |  {:2.2f}\".format(\"Recall 0\", scores_old[1][0], scores_new[1][0]))\n",
    "    print(\"{:15s}= {:2.2f}  |  {:2.2f}\".format(\"F-score 1\", scores_old[2][1], scores_new[2][1]))\n",
    "    print(\"{:15s}= {:2.2f}  |  {:2.2f}\".format(\"F-score 0\", scores_old[2][0], scores_new[2][0]))\n",
    "\n",
    "    print(\"\\n{:14s} : fixed = {:4d} ({:3.3f}%)  |  falsified = {:4d} ({:3.3f}%)\"\\\n",
    "          .format(\"Total\", total_corrected, (total_corrected / valid_len * 100), total_falsified,\\\n",
    "                  (total_falsified / valid_len * 100) ))\n",
    "    print(\"{:14s} : fixed = {:4d} ({:3.3f}%)  |  introduced = {:4d} ({:3.3f}%)\"\\\n",
    "          .format(\"False positives\" ,false_positives_fixed , false_positives_fixed / valid_len * 100 \\\n",
    "            , false_positives_introduced, false_positives_introduced / valid_len * 100))\n",
    "    print(\"{:14s} : fixed = {:4d} ({:3.3f}%)  |  introduced = {:4d} ({:3.3f}%)\"\\\n",
    "          .format(\"False negatives\" ,false_negatives_fixed , false_negatives_fixed / valid_len * 100\\\n",
    "            ,false_negatives_introduced, false_negatives_introduced / valid_len * 100))\n",
    "    \n",
    "#perform spell-fixing as a preprocess step\n",
    "if (1 == 0):\n",
    "    cv = CountVectorizer(lowercase = False, token_pattern=\"[\\S]+\",tokenizer=None)\n",
    "    cv_fit = cv.fit_transform(list(train_df['comment_text']) + list(valid_df['comment_text']))\n",
    "    word_list = cv.get_feature_names();    \n",
    "    counts = np.asarray(cv_fit.sum(axis=0))[0]\n",
    "    freq_dict = dict(zip(word_list, counts))\n",
    "    train_df1 = train_df.copy()\n",
    "    valid_df1 = valid_df.copy()\n",
    "    train_df1['comment_text'] = train_df1['comment_text'].apply(lambda x: spellfix_toxic_words(x, freq_dict))\n",
    "    valid_df1['comment_text'] = valid_df1['comment_text'].apply(lambda x: spellfix_toxic_words(x, freq_dict))\n",
    "\n",
    "    \n",
    "#use differently pre-processed data\n",
    "#train_df = pd.read_csv(\"data/pre_processed/_NEG_for_negations/train_negations_fliped.csv\", usecols = fields)\n",
    "#train_df = train_df[:int(len(train_df) * 1/4)]\n",
    "#train_df.dropna(inplace = True)\n",
    "#valid_df = pd.read_csv(\"data/pre_processed/_NEG_for_negations/train_negations_fliped.csv\", usecols = fields)\n",
    "#valid_df.dropna(inplace = True)\n",
    "\n",
    "compare_different_approaches(res, train_df, \\\n",
    "                                valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting missclassified examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b =  [-1.05166094]\n",
      "no much Chinese please . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.86 ----\n",
      "                          sum toxic : 0.87  |  -0.01 : sum non-toxic                      \n",
      "\n",
      "             chinese - (w=0.94/v=0.42) 0.40 | -0.01 (w=-0.03/v=0.17) - much                \n",
      "        much chinese - (w=0.36/v=0.69) 0.25 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             no much - (w=0.49/v=0.42) 0.21 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                  no - (w=0.06/v=0.19) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "              please - (w=0.01/v=0.31) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : No tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Another brilliant lefty who have choose to ruin his life for a petty political prank . What be this knuckleheads learn in school . It certainly be not common sense . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.47 ----\n",
      "                          sum toxic : 1.10  |  -0.64 : sum non-toxic                      \n",
      "\n",
      "        knuckleheads - (w=1.12/v=0.21) 0.24 | -0.07 (w=-0.46/v=0.15) - brilliant           \n",
      "   this knuckleheads - (w=0.51/v=0.25) 0.13 | -0.06 (w=-0.61/v=0.10) - what be             \n",
      "               lefty - (w=0.83/v=0.15) 0.12 | -0.05 (w=-0.24/v=0.23) - for petty           \n",
      "        it certainly - (w=0.68/v=0.16) 0.11 | -0.05 (w=-0.75/v=0.06) - be not              \n",
      "        common sense - (w=0.57/v=0.14) 0.08 | -0.04 (w=-0.40/v=0.11) - sense               \n",
      "                 his - (w=0.88/v=0.07) 0.06 | -0.04 (w=-0.33/v=0.11) - choose              \n",
      "                ruin - (w=0.39/v=0.14) 0.06 | -0.03 (w=-0.22/v=0.15) - certainly be        \n",
      "               petty - (w=0.31/v=0.16) 0.05 | -0.03 (w=-0.30/v=0.10) - who have            \n",
      "           choose to - (w=0.33/v=0.13) 0.04 | -0.03 (w=-0.20/v=0.15) - in school           \n",
      "          not common - (w=0.20/v=0.21) 0.04 | -0.03 (w=-0.13/v=0.21) - lefty who           \n",
      "                  be - (w=0.76/v=0.05) 0.04 | -0.03 (w=-0.71/v=0.04) - not                 \n",
      "             another - (w=0.38/v=0.09) 0.03 | -0.02 (w=-0.15/v=0.16) - have choose         \n",
      "                this - (w=0.69/v=0.05) 0.03 | -0.02 (w=-0.21/v=0.11) - common              \n",
      "                what - (w=0.26/v=0.06) 0.01 | -0.02 (w=-0.24/v=0.09) - life                \n",
      "               prank - (w=0.07/v=0.21) 0.01 | -0.02 (w=-0.56/v=0.04) - in                  \n",
      "            life for - (w=0.07/v=0.17) 0.01 | -0.02 (w=-0.19/v=0.11) - certainly           \n",
      "           school it - (w=0.06/v=0.19) 0.01 | -0.01 (w=-0.14/v=0.10) - school              \n",
      "               learn - (w=0.10/v=0.11) 0.01 | -0.01 (w=-0.06/v=0.22) - ruin his            \n",
      "             be this - (w=0.08/v=0.12) 0.01 | -0.01 (w=-0.21/v=0.04) - for                 \n",
      "     petty political - (w=0.00/v=0.26) 0.00 | -0.01 (w=-0.04/v=0.18) - to ruin             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.14/v=0.04) - it                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.15/v=0.03) - have                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.04/v=0.10) - political           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.10/v=0.03) - to                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.19) - learn in            \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.06) - who                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.23) - another brilliant   \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.15) - his life            \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : ['knuckleheads']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "The Clinton have be a crime family . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: -0.01 ----\n",
      "                          sum toxic : 0.19  |  -0.20 : sum non-toxic                      \n",
      "\n",
      "             clinton - (w=0.36/v=0.27) 0.10 | -0.09 (w=-0.23/v=0.37) - the clinton         \n",
      "                  be - (w=0.76/v=0.07) 0.05 | -0.07 (w=-0.36/v=0.19) - have be             \n",
      "               crime - (w=0.07/v=0.28) 0.02 | -0.02 (w=-0.10/v=0.24) - family              \n",
      "        clinton have - (w=0.04/v=0.38) 0.01 | -0.01 (w=-0.15/v=0.09) - have                \n",
      "        crime family - (w=0.01/v=0.51) 0.00 | -0.01 (w=-0.11/v=0.07) - the                 \n",
      "            be crime - (w=0.01/v=0.44) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : ['crime, crime family']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Donald be a duck and go for a swim with his big Mouth . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.50 ----\n",
      "                          sum toxic : 0.86  |  -0.36 : sum non-toxic                      \n",
      "\n",
      "               mouth - (w=1.43/v=0.19) 0.27 | -0.19 (w=-0.58/v=0.33) - be duck             \n",
      "                duck - (w=0.61/v=0.23) 0.14 | -0.04 (w=-0.13/v=0.33) - swim with           \n",
      "           donald be - (w=0.36/v=0.25) 0.09 | -0.04 (w=-0.17/v=0.24) - swim                \n",
      "                 his - (w=0.88/v=0.10) 0.09 | -0.02 (w=-0.14/v=0.17) - donald              \n",
      "            duck and - (w=0.28/v=0.29) 0.08 | -0.02 (w=-0.16/v=0.13) - big                 \n",
      "           big mouth - (w=0.16/v=0.29) 0.05 | -0.02 (w=-0.09/v=0.19) - with his            \n",
      "              go for - (w=0.20/v=0.21) 0.04 | -0.01 (w=-0.21/v=0.06) - for                 \n",
      "                  be - (w=0.76/v=0.04) 0.03 | -0.01 (w=-0.02/v=0.37) - for swim            \n",
      "             his big - (w=0.08/v=0.28) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                  go - (w=0.20/v=0.09) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 and - (w=0.29/v=0.05) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                with - (w=0.12/v=0.07) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "              and go - (w=0.03/v=0.20) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : No tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "candidate come across a a adult and the other be pathetically juvenile . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.53 ----\n",
      "                          sum toxic : 0.74  |  -0.22 : sum non-toxic                      \n",
      "\n",
      "        pathetically - (w=1.14/v=0.32) 0.36 | -0.07 (w=-0.26/v=0.26) - juvenile            \n",
      "         come across - (w=0.51/v=0.27) 0.13 | -0.04 (w=-0.10/v=0.36) - be pathetically     \n",
      "           adult and - (w=0.32/v=0.28) 0.09 | -0.03 (w=-0.07/v=0.38) - candidate come      \n",
      "            other be - (w=0.36/v=0.23) 0.08 | -0.03 (w=-0.14/v=0.18) - candidate           \n",
      "                  be - (w=0.76/v=0.04) 0.03 | -0.02 (w=-0.21/v=0.12) - and the             \n",
      "                 and - (w=0.29/v=0.05) 0.01 | -0.02 (w=-0.17/v=0.11) - other               \n",
      "               adult - (w=0.05/v=0.20) 0.01 | -0.01 (w=-0.03/v=0.41) - pathetically juvenile\n",
      "              across - (w=0.04/v=0.19) 0.01 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "                come - (w=0.03/v=0.12) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "           the other - (w=0.02/v=0.16) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Screw you and your destruction of wildlife all for taint beef . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.85 ----\n",
      "                          sum toxic : 1.36  |  -0.51 : sum non-toxic                      \n",
      "\n",
      "           screw you - (w=1.90/v=0.30) 0.57 | -0.11 (w=-0.49/v=0.23) - all for             \n",
      "               screw - (w=2.62/v=0.21) 0.55 | -0.10 (w=-0.39/v=0.26) - beef                \n",
      "                your - (w=1.35/v=0.09) 0.13 | -0.10 (w=-0.42/v=0.23) - wildlife            \n",
      "                 you - (w=0.65/v=0.07) 0.04 | -0.06 (w=-0.24/v=0.26) - taint               \n",
      "         destruction - (w=0.11/v=0.23) 0.03 | -0.04 (w=-0.15/v=0.30) - of wildlife         \n",
      "                 all - (w=0.19/v=0.09) 0.02 | -0.03 (w=-0.17/v=0.20) - and your            \n",
      "                 and - (w=0.29/v=0.05) 0.01 | -0.03 (w=-0.13/v=0.25) - destruction of      \n",
      "             you and - (w=0.07/v=0.18) 0.01 | -0.01 (w=-0.21/v=0.07) - for                 \n",
      "        wildlife all - (w=0.01/v=0.40) 0.00 | -0.01 (w=-0.03/v=0.39) - your destruction    \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.05) - of                  \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: N-Tox. Ass. Stopword in Bigrams\n",
      "Words    : ['all for, beef, wildlife']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Way to send that IS scoundrel to his maker . He get access to his virgin soon than he ask for . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.68 ----\n",
      "                          sum toxic : 1.04  |  -0.37 : sum non-toxic                      \n",
      "\n",
      "           scoundrel - (w=1.73/v=0.21) 0.36 | -0.08 (w=-0.41/v=0.20) - he ask              \n",
      "                 his - (w=0.88/v=0.15) 0.13 | -0.06 (w=-0.44/v=0.13) - access              \n",
      "              virgin - (w=0.60/v=0.20) 0.12 | -0.06 (w=-0.38/v=0.15) - ask for             \n",
      "            maker he - (w=0.32/v=0.27) 0.09 | -0.05 (w=-0.37/v=0.15) - access to           \n",
      "                  he - (w=0.49/v=0.14) 0.07 | -0.03 (w=-0.15/v=0.20) - soon than           \n",
      "                  is - (w=0.40/v=0.11) 0.05 | -0.03 (w=-0.26/v=0.11) - ask                 \n",
      "              to his - (w=0.16/v=0.28) 0.04 | -0.03 (w=-0.33/v=0.08) - way                 \n",
      "           his maker - (w=0.15/v=0.28) 0.04 | -0.01 (w=-0.10/v=0.10) - to                  \n",
      "               maker - (w=0.16/v=0.17) 0.03 | -0.01 (w=-0.21/v=0.05) - for                 \n",
      "             to send - (w=0.12/v=0.17) 0.02 | -0.01 (w=-0.02/v=0.28) - scoundrel to        \n",
      "                soon - (w=0.16/v=0.12) 0.02 | -0.01 (w=-0.04/v=0.12) - way to              \n",
      "          get access - (w=0.08/v=0.22) 0.02 | -0.00 (w=-0.06/v=0.04) - that                \n",
      "           send that - (w=0.07/v=0.22) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             that is - (w=0.06/v=0.20) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                send - (w=0.10/v=0.12) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                than - (w=0.13/v=0.08) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "              he get - (w=0.05/v=0.15) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "          his virgin - (w=0.02/v=0.28) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 get - (w=0.03/v=0.07) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             than he - (w=0.00/v=0.18) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "And Congress and state Houses and Senates be chuck full of Republican walk dead zombie . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.60 ----\n",
      "                          sum toxic : 0.76  |  -0.16 : sum non-toxic                      \n",
      "\n",
      "                dead - (w=1.27/v=0.14) 0.17 | -0.07 (w=-0.31/v=0.22) - houses              \n",
      "              zombie - (w=0.69/v=0.20) 0.14 | -0.02 (w=-0.13/v=0.19) - of republican       \n",
      "             full of - (w=0.82/v=0.15) 0.12 | -0.02 (w=-0.19/v=0.13) - walk                \n",
      "         dead zombie - (w=0.19/v=0.28) 0.05 | -0.02 (w=-0.22/v=0.09) - state               \n",
      "               chuck - (w=0.26/v=0.19) 0.05 | -0.01 (w=-0.04/v=0.28) - senates             \n",
      "        congress and - (w=0.26/v=0.18) 0.05 | -0.01 (w=-0.02/v=0.27) - be chuck            \n",
      "           walk dead - (w=0.15/v=0.25) 0.04 | -0.00 (w=-0.01/v=0.20) - and congress        \n",
      "          republican - (w=0.32/v=0.11) 0.04 | -0.00 (w=-0.02/v=0.13) - congress            \n",
      "                full - (w=0.30/v=0.12) 0.04 | -0.00 (w=-0.01/v=0.28) - houses and          \n",
      "                 and - (w=0.29/v=0.11) 0.03 | -0.00 (w=-0.00/v=0.04) - of                  \n",
      "                  be - (w=0.76/v=0.03) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "           and state - (w=0.10/v=0.16) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "          chuck full - (w=0.00/v=0.29) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "     republican walk - (w=0.00/v=0.29) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "        state houses - (w=0.00/v=0.29) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : disagree\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "They be much animal than the goat disgust . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.97 ----\n",
      "                          sum toxic : 1.33  |  -0.36 : sum non-toxic                      \n",
      "\n",
      "             disgust - (w=4.38/v=0.26) 1.16 | -0.21 (w=-0.49/v=0.42) - the goat            \n",
      "             they be - (w=0.28/v=0.16) 0.04 | -0.07 (w=-0.20/v=0.35) - goat                \n",
      "                  be - (w=0.76/v=0.05) 0.04 | -0.04 (w=-0.22/v=0.19) - be much             \n",
      "              animal - (w=0.10/v=0.26) 0.03 | -0.03 (w=-0.07/v=0.45) - animal than         \n",
      "            than the - (w=0.12/v=0.22) 0.03 | -0.01 (w=-0.11/v=0.05) - the                 \n",
      "                than - (w=0.13/v=0.14) 0.02 | -0.00 (w=-0.01/v=0.44) - much animal         \n",
      "                they - (w=0.14/v=0.11) 0.02 | -0.00 (w=-0.03/v=0.11) - much                \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: \n",
      "Words    : ['the goat']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "of the major issue with drone killing be that it change war since it require no courage to pilot and kill . It also dehumanize the battle so that they be similar to a video game . I do not say they be bad in every possible way . I say they be coward . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.88 ----\n",
      "                          sum toxic : 1.74  |  -0.86 : sum non-toxic                      \n",
      "\n",
      "              coward - (w=6.21/v=0.11) 0.66 | -0.06 (w=-0.55/v=0.12) - drone               \n",
      "                kill - (w=3.16/v=0.07) 0.24 | -0.06 (w=-0.41/v=0.14) - bad in              \n",
      "             killing - (w=1.57/v=0.12) 0.19 | -0.05 (w=-0.44/v=0.10) - in every            \n",
      "           be coward - (w=0.73/v=0.13) 0.10 | -0.04 (w=-0.41/v=0.11) - similar to          \n",
      "          dehumanize - (w=0.52/v=0.15) 0.08 | -0.04 (w=-0.31/v=0.12) - the battle          \n",
      "             kill it - (w=0.54/v=0.13) 0.07 | -0.04 (w=-0.33/v=0.11) - pilot               \n",
      "          courage to - (w=0.50/v=0.12) 0.06 | -0.03 (w=-0.30/v=0.11) - since it            \n",
      "                  be - (w=0.76/v=0.08) 0.06 | -0.03 (w=-0.17/v=0.19) - say they            \n",
      "             they be - (w=0.28/v=0.17) 0.05 | -0.03 (w=-0.45/v=0.06) - be that             \n",
      "          no courage - (w=0.26/v=0.16) 0.04 | -0.03 (w=-0.35/v=0.07) - that they           \n",
      "          be similar - (w=0.34/v=0.12) 0.04 | -0.02 (w=-0.16/v=0.15) - war since           \n",
      "           pilot and - (w=0.18/v=0.14) 0.02 | -0.02 (w=-0.37/v=0.06) - issue               \n",
      "                 bad - (w=0.34/v=0.07) 0.02 | -0.02 (w=-0.21/v=0.11) - and kill            \n",
      "              do not - (w=0.55/v=0.04) 0.02 | -0.02 (w=-0.35/v=0.07) - since               \n",
      "              be bad - (w=0.20/v=0.10) 0.02 | -0.02 (w=-0.22/v=0.10) - battle              \n",
      "                they - (w=0.14/v=0.11) 0.02 | -0.02 (w=-0.28/v=0.08) - game                \n",
      "               every - (w=0.24/v=0.06) 0.02 | -0.02 (w=-0.25/v=0.08) - major               \n",
      "          it require - (w=0.07/v=0.13) 0.01 | -0.02 (w=-0.12/v=0.16) - way say             \n",
      "                 and - (w=0.29/v=0.02) 0.01 | -0.02 (w=-0.71/v=0.03) - not                 \n",
      "                with - (w=0.12/v=0.04) 0.00 | -0.02 (w=-0.17/v=0.11) - issue with          \n",
      "            possible - (w=0.04/v=0.08) 0.00 | -0.02 (w=-0.57/v=0.03) - do                  \n",
      "             it also - (w=0.03/v=0.11) 0.00 | -0.02 (w=-0.33/v=0.05) - way                 \n",
      "             so that - (w=0.03/v=0.09) 0.00 | -0.02 (w=-0.28/v=0.06) - change              \n",
      "      every possible - (w=0.02/v=0.15) 0.00 | -0.02 (w=-0.16/v=0.11) - courage             \n",
      "             that it - (w=0.04/v=0.08) 0.00 | -0.02 (w=-0.13/v=0.14) - video game          \n",
      "          killing be - (w=0.02/v=0.16) 0.00 | -0.02 (w=-0.38/v=0.04) - of the              \n",
      "                  no - (w=0.06/v=0.04) 0.00 | -0.02 (w=-0.56/v=0.03) - in                  \n",
      "          with drone - (w=0.01/v=0.16) 0.00 | -0.02 (w=-0.20/v=0.08) - require             \n",
      "             game do - (w=0.01/v=0.14) 0.00 | -0.01 (w=-0.10/v=0.15) - to video            \n",
      "           battle so - (w=0.00/v=0.19) 0.00 | -0.01 (w=-0.14/v=0.09) - it                  \n",
      "      dehumanize the - (w=0.00/v=0.18) 0.00 | -0.01 (w=-0.08/v=0.14) - major issue         \n",
      "       drone killing - (w=0.00/v=0.18) 0.00 | -0.01 (w=-0.11/v=0.09) - video               \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.06/v=0.15) - require no          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.07/v=0.09) - not say             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.05/v=0.11) - the major           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.06/v=0.10) - say                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.15) - possible way        \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.10/v=0.05) - to                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.09) - similar             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.06/v=0.05) - that                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.06/v=0.04) - so                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.16) - to pilot            \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.06) - also                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.08) - war                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.13) - it change           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.02) - of                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.17) - change war          \n",
      "\n",
      "\n",
      "Category : disagree\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "I hear much and much criminal use the I make a mistake defense Hillary be a pioneer amongst criminal . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.56 ----\n",
      "                          sum toxic : 0.88  |  -0.32 : sum non-toxic                      \n",
      "\n",
      "            criminal - (w=1.37/v=0.32) 0.44 | -0.07 (w=-0.40/v=0.17) - mistake             \n",
      "          hillary be - (w=0.79/v=0.21) 0.17 | -0.06 (w=-0.19/v=0.33) - criminal use        \n",
      "             pioneer - (w=0.24/v=0.26) 0.06 | -0.05 (w=-0.28/v=0.16) - and much            \n",
      "             hillary - (w=0.37/v=0.15) 0.06 | -0.03 (w=-0.15/v=0.19) - much and            \n",
      "            the make - (w=0.17/v=0.24) 0.04 | -0.02 (w=-0.14/v=0.18) - defense             \n",
      "                  be - (w=0.76/v=0.04) 0.03 | -0.02 (w=-0.08/v=0.29) - much criminal       \n",
      "             use the - (w=0.17/v=0.17) 0.03 | -0.02 (w=-0.05/v=0.33) - be pioneer          \n",
      "             amongst - (w=0.10/v=0.23) 0.02 | -0.02 (w=-0.06/v=0.26) - hear much           \n",
      "                 use - (w=0.15/v=0.11) 0.02 | -0.01 (w=-0.13/v=0.09) - make                \n",
      "                 and - (w=0.29/v=0.05) 0.01 | -0.01 (w=-0.04/v=0.14) - hear                \n",
      "        make mistake - (w=0.01/v=0.24) 0.00 | -0.01 (w=-0.03/v=0.15) - much                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "If you be not a socialist in your 20s you have no heart if you be still a socialist in your 40s you have no brain . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.56 ----\n",
      "                          sum toxic : 1.02  |  -0.45 : sum non-toxic                      \n",
      "\n",
      "               brain - (w=1.87/v=0.12) 0.23 | -0.11 (w=-0.55/v=0.19) - 40s                 \n",
      "                your - (w=1.35/v=0.12) 0.16 | -0.05 (w=-0.23/v=0.22) - in your             \n",
      "              you be - (w=0.91/v=0.16) 0.14 | -0.04 (w=-0.75/v=0.06) - be not              \n",
      "            no brain - (w=0.60/v=0.20) 0.12 | -0.04 (w=-0.56/v=0.08) - in                  \n",
      "                 you - (w=0.65/v=0.17) 0.11 | -0.04 (w=-0.19/v=0.21) - not socialist       \n",
      "            no heart - (w=0.23/v=0.21) 0.05 | -0.04 (w=-0.31/v=0.12) - heart               \n",
      "             have no - (w=0.24/v=0.19) 0.04 | -0.03 (w=-0.24/v=0.11) - if                  \n",
      "                  be - (w=0.76/v=0.05) 0.04 | -0.03 (w=-0.15/v=0.17) - if you              \n",
      "           socialist - (w=0.13/v=0.27) 0.03 | -0.03 (w=-0.71/v=0.04) - not                 \n",
      "        socialist in - (w=0.08/v=0.42) 0.03 | -0.02 (w=-0.19/v=0.11) - be still            \n",
      "     still socialist - (w=0.07/v=0.25) 0.02 | -0.01 (w=-0.04/v=0.25) - 40s you             \n",
      "            you have - (w=0.09/v=0.18) 0.02 | -0.01 (w=-0.13/v=0.08) - still               \n",
      "                  no - (w=0.06/v=0.12) 0.01 | -0.01 (w=-0.15/v=0.07) - have                \n",
      "                 20s - (w=0.01/v=0.19) 0.00 | -0.00 (w=-0.02/v=0.22) - heart if            \n",
      "            your 20s - (w=0.00/v=0.25) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "You donkey I be face the same choice too . Everyone face this choice before they actually make the choice . And people who buy year ago be well off . Or year ago . Or just about anytime . What a donkey . lol . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.75 ----\n",
      "                          sum toxic : 1.40  |  -0.64 : sum non-toxic                      \n",
      "\n",
      "              donkey - (w=2.80/v=0.28) 0.77 | -0.11 (w=-0.42/v=0.26) - choice              \n",
      "                face - (w=0.59/v=0.16) 0.10 | -0.06 (w=-0.34/v=0.17) - year ago            \n",
      "         what donkey - (w=0.38/v=0.19) 0.07 | -0.04 (w=-0.27/v=0.16) - this choice         \n",
      "             or just - (w=0.46/v=0.11) 0.05 | -0.04 (w=-0.40/v=0.11) - year                \n",
      "       about anytime - (w=0.25/v=0.19) 0.05 | -0.03 (w=-0.26/v=0.13) - they actually       \n",
      "             who buy - (w=0.33/v=0.13) 0.04 | -0.03 (w=-0.30/v=0.11) - before they         \n",
      "                  be - (w=0.76/v=0.04) 0.03 | -0.03 (w=-0.46/v=0.07) - actually            \n",
      "       choice before - (w=0.17/v=0.18) 0.03 | -0.03 (w=-0.16/v=0.19) - donkey be           \n",
      "            everyone - (w=0.35/v=0.08) 0.03 | -0.03 (w=-0.26/v=0.12) - well off            \n",
      "            face the - (w=0.21/v=0.12) 0.03 | -0.02 (w=-0.20/v=0.12) - just about          \n",
      "                 off - (w=0.39/v=0.07) 0.03 | -0.02 (w=-0.24/v=0.09) - make the            \n",
      "                this - (w=0.69/v=0.04) 0.02 | -0.02 (w=-0.10/v=0.19) - too everyone        \n",
      "         same choice - (w=0.14/v=0.18) 0.02 | -0.02 (w=-0.15/v=0.12) - the choice          \n",
      "                 you - (w=0.65/v=0.03) 0.02 | -0.02 (w=-0.14/v=0.13) - choice and          \n",
      "              ago or - (w=0.09/v=0.16) 0.01 | -0.02 (w=-0.10/v=0.17) - buy year            \n",
      "          and people - (w=0.13/v=0.11) 0.01 | -0.01 (w=-0.19/v=0.08) - buy                 \n",
      "                just - (w=0.24/v=0.05) 0.01 | -0.01 (w=-0.06/v=0.20) - you donkey          \n",
      "                what - (w=0.26/v=0.04) 0.01 | -0.01 (w=-0.13/v=0.09) - or                  \n",
      "             be well - (w=0.09/v=0.09) 0.01 | -0.01 (w=-0.08/v=0.15) - off or              \n",
      "              people - (w=0.17/v=0.05) 0.01 | -0.01 (w=-0.19/v=0.05) - about               \n",
      "                 and - (w=0.29/v=0.03) 0.01 | -0.01 (w=-0.05/v=0.15) - face this           \n",
      "                they - (w=0.14/v=0.04) 0.01 | -0.01 (w=-0.06/v=0.12) - be face             \n",
      "              before - (w=0.08/v=0.07) 0.01 | -0.01 (w=-0.10/v=0.07) - the same            \n",
      "                 lol - (w=0.06/v=0.09) 0.01 | -0.01 (w=-0.12/v=0.06) - well                \n",
      "       actually make - (w=0.04/v=0.13) 0.01 | -0.01 (w=-0.13/v=0.05) - make                \n",
      "                same - (w=0.06/v=0.06) 0.00 | -0.01 (w=-0.05/v=0.12) - anytime             \n",
      "             or year - (w=0.01/v=0.12) 0.00 | -0.01 (w=-0.06/v=0.08) - people who          \n",
      "       everyone face - (w=0.00/v=0.20) 0.00 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.13) - ago be              \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.16) - ago                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.18) - choice too          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.05) - who                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.06) - too                 \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : ['donkey']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "In day Trump be hold a rally in Florida to soothe his ego perhaps he can find a sucker in the crowd . \n",
      "True label: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-                                   ---- Result: 0.09 ----\n",
      "                          sum toxic : 0.91  |  -0.81 : sum non-toxic                      \n",
      "\n",
      "              sucker - (w=2.29/v=0.18) 0.40 | -0.15 (w=-0.66/v=0.23) - soothe              \n",
      "            trump be - (w=1.41/v=0.12) 0.16 | -0.09 (w=-0.46/v=0.19) - the crowd           \n",
      "               trump - (w=0.90/v=0.08) 0.07 | -0.07 (w=-0.56/v=0.13) - in                  \n",
      "                 his - (w=0.88/v=0.08) 0.07 | -0.07 (w=-0.46/v=0.15) - be hold             \n",
      "                  he - (w=0.49/v=0.07) 0.04 | -0.06 (w=-0.27/v=0.22) - rally in            \n",
      "           sucker in - (w=0.14/v=0.25) 0.03 | -0.06 (w=-0.49/v=0.12) - perhaps             \n",
      "                 ego - (w=0.16/v=0.17) 0.03 | -0.05 (w=-0.50/v=0.10) - find                \n",
      "                  be - (w=0.76/v=0.03) 0.02 | -0.04 (w=-0.35/v=0.11) - hold                \n",
      "            can find - (w=0.14/v=0.16) 0.02 | -0.03 (w=-0.14/v=0.23) - day trump           \n",
      "          hold rally - (w=0.08/v=0.25) 0.02 | -0.03 (w=-0.46/v=0.06) - can                 \n",
      "          perhaps he - (w=0.10/v=0.20) 0.02 | -0.03 (w=-0.27/v=0.10) - day                 \n",
      "              he can - (w=0.07/v=0.13) 0.01 | -0.03 (w=-0.10/v=0.26) - to soothe           \n",
      "              in the - (w=0.09/v=0.07) 0.01 | -0.03 (w=-0.09/v=0.28) - soothe his          \n",
      "             his ego - (w=0.01/v=0.21) 0.00 | -0.02 (w=-0.13/v=0.19) - in florida          \n",
      "          florida to - (w=0.01/v=0.25) 0.00 | -0.02 (w=-0.12/v=0.17) - florida             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.02 (w=-0.13/v=0.15) - crowd               \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.05/v=0.19) - in day              \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.04/v=0.16) - rally               \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.10/v=0.04) - to                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.03) - the                 \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : ['sucker']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Columnists like her be part of the reason people be not read the Globe . or the Star for that mater It s like GM year ago . make million of car car nobody want to buy because they be such poor quality . She be talk about use laugh wit and homour to skewer Trump but be not the little bite funny while do it . People vote with their money and they be not support this moribund drivel . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.25 ----\n",
      "                          sum toxic : 1.20  |  -0.96 : sum non-toxic                      \n",
      "\n",
      "              drivel - (w=1.17/v=0.10) 0.12 | -0.09 (w=-0.75/v=0.12) - be not              \n",
      "             be such - (w=1.23/v=0.09) 0.11 | -0.07 (w=-0.90/v=0.08) - be talk             \n",
      "                  be - (w=0.76/v=0.10) 0.08 | -0.06 (w=-0.48/v=0.13) - car                 \n",
      "                 wit - (w=0.70/v=0.11) 0.07 | -0.06 (w=-0.70/v=0.08) - star                \n",
      "         their money - (w=0.62/v=0.09) 0.06 | -0.05 (w=-0.50/v=0.11) - while do            \n",
      "            like her - (w=0.36/v=0.11) 0.04 | -0.05 (w=-0.71/v=0.07) - not                 \n",
      "               trump - (w=0.90/v=0.04) 0.04 | -0.04 (w=-0.38/v=0.11) - her be              \n",
      "                 she - (w=0.69/v=0.06) 0.04 | -0.03 (w=-0.22/v=0.12) - it people           \n",
      "           about use - (w=0.28/v=0.12) 0.03 | -0.02 (w=-0.34/v=0.07) - year ago            \n",
      "           money and - (w=0.38/v=0.08) 0.03 | -0.02 (w=-0.39/v=0.06) - reason              \n",
      "                such - (w=0.53/v=0.06) 0.03 | -0.02 (w=-0.25/v=0.08) - the globe           \n",
      "                 her - (w=0.52/v=0.06) 0.03 | -0.02 (w=-0.18/v=0.11) - vote with           \n",
      "              she be - (w=0.41/v=0.07) 0.03 | -0.02 (w=-0.39/v=0.05) - money               \n",
      "              little - (w=0.59/v=0.05) 0.03 | -0.02 (w=-0.24/v=0.08) - be part             \n",
      "             they be - (w=0.28/v=0.10) 0.03 | -0.02 (w=-0.29/v=0.06) - not the             \n",
      "                poor - (w=0.41/v=0.07) 0.03 | -0.02 (w=-0.40/v=0.04) - year                \n",
      "                like - (w=0.34/v=0.08) 0.03 | -0.02 (w=-0.16/v=0.10) - little bite         \n",
      "                  gm - (w=0.26/v=0.10) 0.03 | -0.02 (w=-0.57/v=0.03) - do                  \n",
      "              to buy - (w=0.31/v=0.08) 0.02 | -0.02 (w=-0.26/v=0.06) - part                \n",
      "               mater - (w=0.18/v=0.13) 0.02 | -0.01 (w=-0.17/v=0.08) - million of          \n",
      "           people be - (w=0.31/v=0.07) 0.02 | -0.01 (w=-0.25/v=0.06) - support             \n",
      "            the star - (w=0.21/v=0.10) 0.02 | -0.01 (w=-0.13/v=0.11) - of car              \n",
      "              skewer - (w=0.15/v=0.13) 0.02 | -0.01 (w=-0.38/v=0.04) - of the              \n",
      "                this - (w=0.69/v=0.03) 0.02 | -0.01 (w=-0.17/v=0.08) - the reason          \n",
      "         nobody want - (w=0.17/v=0.11) 0.02 | -0.01 (w=-0.09/v=0.14) - wit and             \n",
      "               while - (w=0.33/v=0.06) 0.02 | -0.01 (w=-0.12/v=0.10) - trump but           \n",
      "               their - (w=0.44/v=0.04) 0.02 | -0.01 (w=-0.35/v=0.03) - but                 \n",
      "        support this - (w=0.14/v=0.10) 0.01 | -0.01 (w=-0.19/v=0.06) - buy                 \n",
      "              people - (w=0.17/v=0.08) 0.01 | -0.01 (w=-0.15/v=0.08) - with their          \n",
      "        make million - (w=0.11/v=0.12) 0.01 | -0.01 (w=-0.16/v=0.07) - funny               \n",
      "          the little - (w=0.15/v=0.08) 0.01 | -0.01 (w=-0.06/v=0.15) - ago make            \n",
      "                 and - (w=0.29/v=0.04) 0.01 | -0.01 (w=-0.12/v=0.07) - read the            \n",
      "                bite - (w=0.15/v=0.07) 0.01 | -0.01 (w=-0.15/v=0.05) - vote                \n",
      "            not read - (w=0.11/v=0.09) 0.01 | -0.01 (w=-0.09/v=0.09) - not support         \n",
      "                they - (w=0.14/v=0.07) 0.01 | -0.01 (w=-0.06/v=0.13) - star for            \n",
      "               laugh - (w=0.12/v=0.08) 0.01 | -0.01 (w=-0.14/v=0.06) - it                  \n",
      "             it like - (w=0.09/v=0.10) 0.01 | -0.01 (w=-0.06/v=0.13) - such poor           \n",
      "                 use - (w=0.15/v=0.05) 0.01 | -0.01 (w=-0.19/v=0.04) - about               \n",
      "             because - (w=0.14/v=0.05) 0.01 | -0.01 (w=-0.11/v=0.07) - the                 \n",
      "                talk - (w=0.10/v=0.06) 0.01 | -0.01 (w=-0.05/v=0.15) - buy because         \n",
      "                want - (w=0.11/v=0.05) 0.00 | -0.01 (w=-0.04/v=0.15) - car car             \n",
      "             million - (w=0.07/v=0.07) 0.00 | -0.01 (w=-0.08/v=0.07) - or the              \n",
      "        because they - (w=0.07/v=0.07) 0.00 | -0.01 (w=-0.21/v=0.03) - for                 \n",
      "              but be - (w=0.05/v=0.08) 0.00 | -0.01 (w=-0.04/v=0.12) - reason people       \n",
      "        poor quality - (w=0.03/v=0.13) 0.00 | -0.01 (w=-0.13/v=0.04) - make                \n",
      "                with - (w=0.12/v=0.03) 0.00 | -0.01 (w=-0.07/v=0.07) - do it               \n",
      "              nobody - (w=0.05/v=0.08) 0.00 | -0.00 (w=-0.13/v=0.04) - or                  \n",
      "             quality - (w=0.04/v=0.08) 0.00 | -0.00 (w=-0.03/v=0.16) - funny while         \n",
      "            for that - (w=0.03/v=0.07) 0.00 | -0.00 (w=-0.08/v=0.05) - want to             \n",
      "             gm year - (w=0.00/v=0.16) 0.00 | -0.00 (w=-0.07/v=0.06) - read                \n",
      "             like gm - (w=0.00/v=0.16) 0.00 | -0.00 (w=-0.10/v=0.04) - to                  \n",
      "          that mater - (w=0.00/v=0.16) 0.00 | -0.00 (w=-0.03/v=0.14) - moribund            \n",
      "          bite funny - (w=0.00/v=0.16) 0.00 | -0.00 (w=-0.05/v=0.07) - and they            \n",
      "           to skewer - (w=0.00/v=0.16) 0.00 | -0.00 (w=-0.02/v=0.16) - columnists          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.06/v=0.02) - that                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.08) - globe               \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.06) - ago                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.07) - talk about          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.10) - people vote         \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.16) - use laugh           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.14) - globe or            \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.06) - part of             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.04) - of                  \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "How childish of Rickie boy . Some see the American flag display in a inappropriate manner and simply let the other person know . And what doe Rickie boy do . Responds with something say the equivalent of at little I have . How moronic . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.97 ----\n",
      "                          sum toxic : 1.46  |  -0.49 : sum non-toxic                      \n",
      "\n",
      "             moronic - (w=5.92/v=0.13) 0.74 | -0.05 (w=-0.43/v=0.13) - the equivalent      \n",
      "            childish - (w=1.06/v=0.12) 0.12 | -0.05 (w=-0.35/v=0.14) - manner and          \n",
      "                 boy - (w=0.45/v=0.18) 0.08 | -0.03 (w=-0.46/v=0.07) - at little           \n",
      "        how childish - (w=0.30/v=0.18) 0.05 | -0.03 (w=-0.27/v=0.13) - equivalent of       \n",
      "         how moronic - (w=0.25/v=0.19) 0.05 | -0.03 (w=-0.22/v=0.15) - boy do              \n",
      "              person - (w=0.53/v=0.07) 0.04 | -0.03 (w=-0.27/v=0.11) - have how            \n",
      "              little - (w=0.59/v=0.06) 0.03 | -0.02 (w=-0.19/v=0.13) - other person        \n",
      "    in inappropriate - (w=0.16/v=0.18) 0.03 | -0.02 (w=-0.22/v=0.10) - what doe            \n",
      "       something say - (w=0.16/v=0.16) 0.03 | -0.02 (w=-0.11/v=0.19) - flag display        \n",
      "            know and - (w=0.21/v=0.11) 0.02 | -0.02 (w=-0.11/v=0.17) - simply let          \n",
      "             display - (w=0.22/v=0.11) 0.02 | -0.02 (w=-0.17/v=0.11) - equivalent          \n",
      "                 let - (w=0.35/v=0.06) 0.02 | -0.02 (w=-0.57/v=0.03) - do                  \n",
      "       inappropriate - (w=0.18/v=0.12) 0.02 | -0.02 (w=-0.56/v=0.03) - in                  \n",
      "             see the - (w=0.25/v=0.08) 0.02 | -0.02 (w=-0.24/v=0.07) - something           \n",
      "               of at - (w=0.14/v=0.13) 0.02 | -0.01 (w=-0.15/v=0.10) - flag                \n",
      "      with something - (w=0.14/v=0.13) 0.02 | -0.01 (w=-0.20/v=0.05) - see                 \n",
      "              simply - (w=0.23/v=0.08) 0.02 | -0.01 (w=-0.12/v=0.09) - the american        \n",
      "            american - (w=0.24/v=0.07) 0.02 | -0.01 (w=-0.03/v=0.38) - rickie              \n",
      "             let the - (w=0.16/v=0.10) 0.02 | -0.01 (w=-0.16/v=0.06) - doe                 \n",
      "                 and - (w=0.29/v=0.05) 0.01 | -0.01 (w=-0.17/v=0.05) - other               \n",
      "            some see - (w=0.09/v=0.16) 0.01 | -0.01 (w=-0.11/v=0.06) - the                 \n",
      "                some - (w=0.24/v=0.05) 0.01 | -0.01 (w=-0.05/v=0.13) - and simply          \n",
      "                 how - (w=0.12/v=0.10) 0.01 | -0.01 (w=-0.05/v=0.10) - manner              \n",
      "                what - (w=0.26/v=0.04) 0.01 | -0.01 (w=-0.04/v=0.14) - american flag       \n",
      "             say the - (w=0.12/v=0.09) 0.01 | -0.00 (w=-0.04/v=0.13) - little have         \n",
      "         childish of - (w=0.05/v=0.19) 0.01 | -0.00 (w=-0.15/v=0.03) - have                \n",
      "                with - (w=0.12/v=0.04) 0.00 | -0.00 (w=-0.06/v=0.05) - say                 \n",
      "                know - (w=0.08/v=0.05) 0.00 | -0.00 (w=-0.06/v=0.04) - at                  \n",
      "           the other - (w=0.02/v=0.07) 0.00 | -0.00 (w=-0.01/v=0.09) - and what            \n",
      "         person know - (w=0.01/v=0.15) 0.00 | -0.00 (w=-0.01/v=0.15) - display in          \n",
      "inappropriate manner - (w=0.00/v=0.19) 0.00 | -0.00 (w=-0.00/v=0.05) - of                  \n",
      "            boy some - (w=0.00/v=0.19) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "            responds - (w=0.00/v=0.19) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: \n",
      "Words    : ['the equivalent, manner and']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Trump need to step aside . His treason and incompetence combine with his mental derangement make him a danger to America . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.99 ----\n",
      "                          sum toxic : 1.39  |  -0.39 : sum non-toxic                      \n",
      "\n",
      "              mental - (w=2.45/v=0.16) 0.40 | -0.09 (w=-0.54/v=0.17) - aside               \n",
      "                 his - (w=0.88/v=0.16) 0.14 | -0.08 (w=-0.57/v=0.14) - step                \n",
      "          trump need - (w=0.51/v=0.21) 0.11 | -0.08 (w=-0.30/v=0.26) - his mental          \n",
      "    and incompetence - (w=0.41/v=0.23) 0.10 | -0.07 (w=-0.31/v=0.24) - treason and         \n",
      "          step aside - (w=0.38/v=0.24) 0.09 | -0.03 (w=-0.17/v=0.18) - make him            \n",
      "          to america - (w=0.45/v=0.20) 0.09 | -0.01 (w=-0.09/v=0.15) - with his            \n",
      "        incompetence - (w=0.42/v=0.18) 0.08 | -0.01 (w=-0.13/v=0.08) - make                \n",
      "               trump - (w=0.90/v=0.08) 0.07 | -0.01 (w=-0.10/v=0.08) - to                  \n",
      "                 him - (w=0.72/v=0.10) 0.07 | -0.01 (w=-0.03/v=0.21) - danger to           \n",
      "         derangement - (w=0.23/v=0.23) 0.05 | -0.00 (w=-0.02/v=0.17) - combine             \n",
      "             to step - (w=0.24/v=0.19) 0.04 | -0.00 (w=-0.00/v=0.28) - his treason         \n",
      "           aside his - (w=0.14/v=0.28) 0.04 | -0.00 (w=-0.00/v=0.21) - combine with        \n",
      "             treason - (w=0.15/v=0.19) 0.03 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             america - (w=0.19/v=0.12) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                need - (w=0.19/v=0.09) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 and - (w=0.29/v=0.04) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "              danger - (w=0.05/v=0.17) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                with - (w=0.12/v=0.06) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             need to - (w=0.04/v=0.10) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Failed to learn tox. Words\n",
      "Category2: N-Tox. Ass. Neutral words\n",
      "Words    : ['treason, mental derangement | step, aside']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "hmm and Trump be try to depopulate the USA by try to cut off people health care and their right and freedom and leave them to die off so he can try to hold onto power . Grab Trumpy by the ballz and twist them real hard . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.50 ----\n",
      "                          sum toxic : 1.25  |  -0.76 : sum non-toxic                      \n",
      "\n",
      "                grab - (w=1.44/v=0.10) 0.15 | -0.06 (w=-0.72/v=0.09) - be try              \n",
      "                 die - (w=1.60/v=0.09) 0.14 | -0.06 (w=-0.38/v=0.17) - usa by              \n",
      "            trump be - (w=1.41/v=0.08) 0.11 | -0.06 (w=-0.39/v=0.15) - power grab          \n",
      "          off people - (w=0.61/v=0.16) 0.09 | -0.06 (w=-0.44/v=0.13) - and freedom         \n",
      "               twist - (w=0.81/v=0.11) 0.09 | -0.05 (w=-0.41/v=0.13) - leave them          \n",
      "           and twist - (w=0.51/v=0.15) 0.08 | -0.05 (w=-0.48/v=0.11) - to hold             \n",
      "                them - (w=0.59/v=0.11) 0.06 | -0.04 (w=-0.24/v=0.15) - off so              \n",
      "              to die - (w=0.51/v=0.12) 0.06 | -0.03 (w=-0.31/v=0.11) - to cut              \n",
      "                 off - (w=0.39/v=0.13) 0.05 | -0.03 (w=-0.29/v=0.11) - care and            \n",
      "               trump - (w=0.90/v=0.05) 0.05 | -0.03 (w=-0.35/v=0.09) - by                  \n",
      "             die off - (w=0.25/v=0.15) 0.04 | -0.03 (w=-0.30/v=0.11) - so he               \n",
      "                 and - (w=0.29/v=0.12) 0.04 | -0.03 (w=-0.30/v=0.10) - hmm                 \n",
      "             the usa - (w=0.33/v=0.09) 0.03 | -0.03 (w=-0.35/v=0.08) - hold                \n",
      "          twist them - (w=0.16/v=0.17) 0.03 | -0.02 (w=-0.23/v=0.11) - onto                \n",
      "                 cut - (w=0.36/v=0.08) 0.03 | -0.02 (w=-0.31/v=0.07) - power               \n",
      "           and their - (w=0.29/v=0.09) 0.03 | -0.02 (w=-0.46/v=0.04) - can                 \n",
      "         their right - (w=0.22/v=0.11) 0.03 | -0.02 (w=-0.20/v=0.07) - hard                \n",
      "              try to - (w=0.11/v=0.21) 0.02 | -0.01 (w=-0.15/v=0.09) - usa                 \n",
      "                  he - (w=0.49/v=0.05) 0.02 | -0.01 (w=-0.11/v=0.10) - and trump           \n",
      "               their - (w=0.44/v=0.05) 0.02 | -0.01 (w=-0.09/v=0.12) - cut off             \n",
      "           and leave - (w=0.18/v=0.11) 0.02 | -0.01 (w=-0.10/v=0.10) - right and           \n",
      "                real - (w=0.24/v=0.07) 0.02 | -0.01 (w=-0.18/v=0.06) - right               \n",
      "                  be - (w=0.76/v=0.02) 0.02 | -0.01 (w=-0.10/v=0.09) - to                  \n",
      "           hold onto - (w=0.06/v=0.14) 0.01 | -0.01 (w=-0.06/v=0.14) - by try              \n",
      "              people - (w=0.17/v=0.05) 0.01 | -0.01 (w=-0.05/v=0.13) - can try             \n",
      "              trumpy - (w=0.05/v=0.15) 0.01 | -0.01 (w=-0.06/v=0.09) - health care         \n",
      "              he can - (w=0.07/v=0.09) 0.01 | -0.00 (w=-0.04/v=0.12) - freedom and         \n",
      "                care - (w=0.08/v=0.07) 0.01 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "              by the - (w=0.06/v=0.06) 0.00 | -0.00 (w=-0.02/v=0.18) - people health       \n",
      "               leave - (w=0.05/v=0.06) 0.00 | -0.00 (w=-0.06/v=0.04) - so                  \n",
      "                 try - (w=0.01/v=0.19) 0.00 | -0.00 (w=-0.02/v=0.09) - freedom             \n",
      "              health - (w=0.03/v=0.08) 0.00 | -0.00 (w=-0.01/v=0.15) - real hard           \n",
      "      depopulate the - (w=0.00/v=0.19) 0.00 | -0.00 (w=-0.00/v=0.17) - hmm and             \n",
      "          depopulate - (w=0.00/v=0.18) 0.00 | -0.00 (w=-0.01/v=0.09) - them to             \n",
      "           them real - (w=0.00/v=0.18) 0.00 | -0.00 (w=-0.00/v=0.18) - onto power          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.19) - to depopulate       \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "She need to close both nostril and shut her mouth very relax for us . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.47 ----\n",
      "                          sum toxic : 0.89  |  -0.43 : sum non-toxic                      \n",
      "\n",
      "                shut - (w=1.60/v=0.15) 0.24 | -0.15 (w=-0.79/v=0.19) - relax               \n",
      "               mouth - (w=1.43/v=0.15) 0.22 | -0.11 (w=-0.47/v=0.24) - her mouth           \n",
      "        both nostril - (w=0.30/v=0.29) 0.09 | -0.06 (w=-0.28/v=0.21) - she need            \n",
      "                 she - (w=0.69/v=0.11) 0.07 | -0.05 (w=-0.38/v=0.12) - close               \n",
      "                 her - (w=0.52/v=0.11) 0.06 | -0.02 (w=-0.13/v=0.19) - to close            \n",
      "             nostril - (w=0.20/v=0.27) 0.06 | -0.02 (w=-0.19/v=0.09) - us                  \n",
      "            shut her - (w=0.19/v=0.28) 0.05 | -0.01 (w=-0.21/v=0.05) - for                 \n",
      "              for us - (w=0.30/v=0.16) 0.05 | -0.00 (w=-0.10/v=0.04) - to                  \n",
      "            and shut - (w=0.08/v=0.21) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                need - (w=0.19/v=0.09) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 and - (w=0.29/v=0.04) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                very - (w=0.11/v=0.10) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             need to - (w=0.04/v=0.10) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                both - (w=0.01/v=0.11) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "         nostril and - (w=0.00/v=0.31) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "           relax for - (w=0.00/v=0.31) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "          very relax - (w=0.00/v=0.31) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "          close both - (w=0.00/v=0.30) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: Trigram needed\n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Trump be also correct when he say his inauguration crowd be the large . And that Ted Cruz have father be responsible for Kennedy have assassination . A person who support a liar be . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.30 ----\n",
      "                          sum toxic : 1.44  |  -1.14 : sum non-toxic                      \n",
      "\n",
      "                liar - (w=6.40/v=0.12) 0.74 | -0.23 (w=-1.22/v=0.19) - liar be             \n",
      "            trump be - (w=1.41/v=0.09) 0.13 | -0.08 (w=-0.48/v=0.17) - say his             \n",
      "                  be - (w=0.76/v=0.10) 0.08 | -0.08 (w=-0.42/v=0.18) - his inauguration    \n",
      "         have father - (w=0.37/v=0.17) 0.06 | -0.08 (w=-0.36/v=0.21) - support liar        \n",
      "               trump - (w=0.90/v=0.06) 0.06 | -0.06 (w=-0.56/v=0.11) - be also             \n",
      "                 his - (w=0.88/v=0.06) 0.06 | -0.06 (w=-0.45/v=0.13) - be responsible      \n",
      "              person - (w=0.53/v=0.09) 0.05 | -0.05 (w=-0.31/v=0.15) - inauguration        \n",
      "              father - (w=0.35/v=0.12) 0.04 | -0.05 (w=-0.46/v=0.10) - correct             \n",
      "        correct when - (w=0.20/v=0.19) 0.04 | -0.04 (w=-0.46/v=0.10) - large               \n",
      "           cruz have - (w=0.18/v=0.19) 0.03 | -0.04 (w=-0.40/v=0.11) - responsible         \n",
      "           father be - (w=0.20/v=0.16) 0.03 | -0.04 (w=-0.23/v=0.17) - ted cruz            \n",
      "                  he - (w=0.49/v=0.06) 0.03 | -0.04 (w=-0.20/v=0.20) - inauguration crowd  \n",
      "            that ted - (w=0.11/v=0.21) 0.02 | -0.04 (w=-0.32/v=0.11) - when he             \n",
      "     responsible for - (w=0.17/v=0.12) 0.02 | -0.03 (w=-0.16/v=0.19) - kennedy have        \n",
      "             kennedy - (w=0.08/v=0.15) 0.01 | -0.03 (w=-0.21/v=0.14) - ted                 \n",
      "                 and - (w=0.29/v=0.03) 0.01 | -0.03 (w=-0.25/v=0.12) - he say              \n",
      "                cruz - (w=0.05/v=0.15) 0.01 | -0.03 (w=-0.16/v=0.16) - assassination       \n",
      "            and that - (w=0.07/v=0.09) 0.01 | -0.02 (w=-0.17/v=0.13) - the large           \n",
      "         who support - (w=0.04/v=0.15) 0.01 | -0.02 (w=-0.25/v=0.08) - support             \n",
      "  have assassination - (w=0.02/v=0.21) 0.00 | -0.02 (w=-0.34/v=0.06) - when                \n",
      "              be the - (w=0.05/v=0.06) 0.00 | -0.02 (w=-0.13/v=0.12) - crowd               \n",
      "            crowd be - (w=0.00/v=0.17) 0.00 | -0.01 (w=-0.11/v=0.13) - person who          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.15/v=0.06) - have                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.21/v=0.04) - for                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.05/v=0.16) - large and           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.04/v=0.20) - also correct        \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.02/v=0.23) - for kennedy         \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.06/v=0.06) - say                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.03) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.08) - also                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.06/v=0.03) - that                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.06) - who                 \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass to tox. Words\n",
      "Category2: N-Tox. Ass. Neutral words\n",
      "Words    : ['liar be, support liar, his inauguration , say his']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "McCraken be a fake doctor a specialist in diversity medcine . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.08 ----\n",
      "                          sum toxic : 0.39  |  -0.31 : sum non-toxic                      \n",
      "\n",
      "             be fake - (w=0.59/v=0.27) 0.16 | -0.17 (w=-0.66/v=0.25) - diversity           \n",
      "         fake doctor - (w=0.25/v=0.42) 0.11 | -0.05 (w=-0.18/v=0.29) - specialist          \n",
      "                fake - (w=0.45/v=0.20) 0.09 | -0.04 (w=-0.56/v=0.07) - in                  \n",
      "                  be - (w=0.76/v=0.05) 0.04 | -0.03 (w=-0.09/v=0.37) - specialist in       \n",
      "   doctor specialist - (w=0.00/v=0.45) 0.00 | -0.02 (w=-0.08/v=0.21) - doctor              \n",
      "        in diversity - (w=0.00/v=0.42) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : No tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "hate be a belief if he call for violence or such fine charge him with incite but until then he have the right to speak regardless of how much a fool he be . the leave doe not get to decide . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.85 ----\n",
      "                          sum toxic : 1.84  |  -0.99 : sum non-toxic                      \n",
      "\n",
      "                fool - (w=10.08/v=0.11) 1.07 | -0.20 (w=-1.51/v=0.13) - to decide           \n",
      "             fool he - (w=0.73/v=0.18) 0.13 | -0.08 (w=-0.55/v=0.15) - he call             \n",
      "                  he - (w=0.49/v=0.17) 0.08 | -0.06 (w=-0.33/v=0.18) - charge him          \n",
      "                hate - (w=0.82/v=0.10) 0.08 | -0.05 (w=-0.46/v=0.11) - regardless of       \n",
      "                 him - (w=0.72/v=0.07) 0.05 | -0.05 (w=-0.51/v=0.10) - fine                \n",
      "           the leave - (w=0.40/v=0.11) 0.04 | -0.04 (w=-0.37/v=0.11) - belief              \n",
      "                such - (w=0.53/v=0.08) 0.04 | -0.04 (w=-0.27/v=0.15) - incite              \n",
      "                  be - (w=0.76/v=0.05) 0.04 | -0.04 (w=-0.40/v=0.10) - how much            \n",
      "            violence - (w=0.32/v=0.11) 0.04 | -0.04 (w=-0.41/v=0.10) - get to              \n",
      "         violence or - (w=0.16/v=0.18) 0.03 | -0.04 (w=-0.21/v=0.19) - leave doe           \n",
      "        for violence - (w=0.15/v=0.18) 0.03 | -0.04 (w=-0.39/v=0.10) - decide              \n",
      "              of how - (w=0.22/v=0.12) 0.03 | -0.04 (w=-0.39/v=0.09) - speak               \n",
      "               he be - (w=0.32/v=0.08) 0.02 | -0.03 (w=-0.26/v=0.14) - then he             \n",
      "             he have - (w=0.24/v=0.09) 0.02 | -0.03 (w=-0.22/v=0.15) - until then          \n",
      "             or such - (w=0.11/v=0.19) 0.02 | -0.02 (w=-0.25/v=0.09) - charge              \n",
      "             hate be - (w=0.10/v=0.17) 0.02 | -0.02 (w=-0.12/v=0.19) - such fine           \n",
      "           the right - (w=0.14/v=0.09) 0.01 | -0.02 (w=-0.71/v=0.03) - not                 \n",
      "               until - (w=0.14/v=0.09) 0.01 | -0.02 (w=-0.12/v=0.15) - him with            \n",
      "                then - (w=0.17/v=0.07) 0.01 | -0.02 (w=-0.35/v=0.05) - but                 \n",
      "            right to - (w=0.11/v=0.10) 0.01 | -0.01 (w=-0.24/v=0.05) - if                  \n",
      "            have the - (w=0.15/v=0.08) 0.01 | -0.01 (w=-0.18/v=0.06) - right               \n",
      "           belief if - (w=0.04/v=0.20) 0.01 | -0.01 (w=-0.16/v=0.07) - doe                 \n",
      "                 how - (w=0.12/v=0.06) 0.01 | -0.01 (w=-0.21/v=0.04) - for                 \n",
      "           but until - (w=0.04/v=0.17) 0.01 | -0.01 (w=-0.04/v=0.20) - be belief           \n",
      "                call - (w=0.08/v=0.08) 0.01 | -0.01 (w=-0.06/v=0.12) - to speak            \n",
      "                with - (w=0.12/v=0.04) 0.01 | -0.01 (w=-0.13/v=0.05) - or                  \n",
      "             not get - (w=0.05/v=0.10) 0.00 | -0.01 (w=-0.06/v=0.11) - regardless          \n",
      "               leave - (w=0.05/v=0.08) 0.00 | -0.01 (w=-0.10/v=0.05) - to                  \n",
      "              be the - (w=0.05/v=0.06) 0.00 | -0.01 (w=-0.04/v=0.12) - call for            \n",
      "               if he - (w=0.02/v=0.10) 0.00 | -0.01 (w=-0.11/v=0.05) - the                 \n",
      "                 get - (w=0.03/v=0.05) 0.00 | -0.00 (w=-0.15/v=0.03) - have                \n",
      "         with incite - (w=0.00/v=0.23) 0.00 | -0.00 (w=-0.05/v=0.09) - doe not             \n",
      "           much fool - (w=0.00/v=0.22) 0.00 | -0.00 (w=-0.03/v=0.05) - much                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.23) - incite but          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.03) - of                  \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: \n",
      "Words    : ['to decide']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "I do not think they eat them just kill them chop them up and sell off the part . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.65 ----\n",
      "                          sum toxic : 1.24  |  -0.59 : sum non-toxic                      \n",
      "\n",
      "                kill - (w=3.16/v=0.13) 0.42 | -0.08 (w=-0.31/v=0.25) - just kill           \n",
      "           kill them - (w=1.50/v=0.22) 0.33 | -0.06 (w=-0.42/v=0.15) - off the             \n",
      "                them - (w=0.59/v=0.27) 0.16 | -0.06 (w=-0.25/v=0.25) - they eat            \n",
      "              up and - (w=0.38/v=0.15) 0.06 | -0.06 (w=-0.30/v=0.20) - and sell            \n",
      "                 off - (w=0.39/v=0.11) 0.04 | -0.05 (w=-0.23/v=0.23) - them just           \n",
      "              do not - (w=0.55/v=0.07) 0.04 | -0.05 (w=-0.24/v=0.22) - sell off            \n",
      "          think they - (w=0.24/v=0.16) 0.04 | -0.05 (w=-0.58/v=0.09) - think               \n",
      "                chop - (w=0.15/v=0.22) 0.03 | -0.04 (w=-0.28/v=0.15) - eat                 \n",
      "                sell - (w=0.21/v=0.13) 0.03 | -0.03 (w=-0.71/v=0.05) - not                 \n",
      "           not think - (w=0.16/v=0.14) 0.02 | -0.03 (w=-0.57/v=0.06) - do                  \n",
      "                just - (w=0.24/v=0.08) 0.02 | -0.03 (w=-0.26/v=0.12) - part                \n",
      "            the part - (w=0.10/v=0.18) 0.02 | -0.02 (w=-0.07/v=0.25) - eat them            \n",
      "                 and - (w=0.29/v=0.04) 0.01 | -0.01 (w=-0.02/v=0.32) - chop them           \n",
      "                  up - (w=0.14/v=0.08) 0.01 | -0.00 (w=-0.11/v=0.03) - the                 \n",
      "                they - (w=0.14/v=0.07) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "             them up - (w=0.00/v=0.20) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "           them chop - (w=0.00/v=0.33) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Failed to learn tox. Words\n",
      "Category2: N-Tox. Ass. Neutral words\n",
      "Words    : ['kill them | just kill, off the, they eat, and sell']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "You really be a bundle of ignorance . Vancouver be on the Coast and -PRON- have in the South of the Province . Too difficult for you . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.97 ----\n",
      "                          sum toxic : 1.51  |  -0.54 : sum non-toxic                      \n",
      "\n",
      "           ignorance - (w=3.95/v=0.17) 0.66 | -0.07 (w=-0.35/v=0.21) - the coast           \n",
      "        of ignorance - (w=0.90/v=0.23) 0.21 | -0.07 (w=-0.31/v=0.23) - coast and           \n",
      "           really be - (w=0.50/v=0.16) 0.08 | -0.06 (w=-0.38/v=0.16) - vancouver           \n",
      "                 you - (w=0.65/v=0.11) 0.07 | -0.06 (w=-0.44/v=0.13) - be on               \n",
      "       too difficult - (w=0.27/v=0.25) 0.07 | -0.06 (w=-0.37/v=0.15) - difficult           \n",
      "                pron - (w=0.94/v=0.06) 0.06 | -0.03 (w=-0.19/v=0.15) - south               \n",
      "        vancouver be - (w=0.26/v=0.22) 0.06 | -0.03 (w=-0.38/v=0.07) - of the              \n",
      "           the south - (w=0.30/v=0.18) 0.05 | -0.03 (w=-0.56/v=0.05) - in                  \n",
      "       difficult for - (w=0.26/v=0.20) 0.05 | -0.02 (w=-0.16/v=0.15) - province            \n",
      "                  be - (w=0.76/v=0.07) 0.05 | -0.02 (w=-0.20/v=0.10) - really              \n",
      "           bundle of - (w=0.15/v=0.27) 0.04 | -0.01 (w=-0.22/v=0.06) - on                  \n",
      "        the province - (w=0.19/v=0.17) 0.03 | -0.01 (w=-0.14/v=0.09) - on the              \n",
      "             for you - (w=0.23/v=0.14) 0.03 | -0.01 (w=-0.07/v=0.17) - coast               \n",
      "          you really - (w=0.09/v=0.16) 0.01 | -0.01 (w=-0.21/v=0.05) - for                 \n",
      "                 and - (w=0.29/v=0.04) 0.01 | -0.01 (w=-0.11/v=0.10) - the                 \n",
      "              in the - (w=0.09/v=0.07) 0.01 | -0.01 (w=-0.03/v=0.29) - be bundle           \n",
      "              bundle - (w=0.02/v=0.23) 0.00 | -0.01 (w=-0.08/v=0.08) - pron have           \n",
      "            south of - (w=0.02/v=0.20) 0.00 | -0.01 (w=-0.15/v=0.04) - have                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.16) - have in             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.13) - and pron            \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.10) - too                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.09) - of                  \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: N-Tox. Ass. Stopword in Bigrams\n",
      "Words    : ['the coast, coast and, vancouver']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "And Notley make sure her Public Sector and other union member get their money while cut back be hit all other non union Albertans just like Trudeau and Horgan Weaver in BC . Typical leave wing crook . \n",
      "True label: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-                                   ---- Result: 0.63 ----\n",
      "                          sum toxic : 1.43  |  -0.80 : sum non-toxic                      \n",
      "\n",
      "               crook - (w=3.45/v=0.12) 0.42 | -0.09 (w=-0.61/v=0.14) - horgan              \n",
      "       typical leave - (w=0.70/v=0.17) 0.12 | -0.06 (w=-0.34/v=0.18) - her public          \n",
      "           all other - (w=0.64/v=0.12) 0.08 | -0.06 (w=-0.45/v=0.13) - notley              \n",
      "              weaver - (w=0.53/v=0.15) 0.08 | -0.06 (w=-0.66/v=0.09) - and other           \n",
      "         their money - (w=0.62/v=0.12) 0.08 | -0.06 (w=-0.29/v=0.19) - union               \n",
      "             typical - (w=0.54/v=0.11) 0.06 | -0.05 (w=-0.33/v=0.14) - cut back            \n",
      "          leave wing - (w=0.44/v=0.11) 0.05 | -0.05 (w=-0.38/v=0.12) - trudeau and         \n",
      "                wing - (w=0.43/v=0.10) 0.04 | -0.04 (w=-0.24/v=0.16) - money while         \n",
      "                 hit - (w=0.43/v=0.10) 0.04 | -0.03 (w=-0.41/v=0.07) - sure                \n",
      "                 her - (w=0.52/v=0.07) 0.04 | -0.03 (w=-0.19/v=0.15) - like trudeau        \n",
      "             trudeau - (w=0.43/v=0.08) 0.04 | -0.03 (w=-0.18/v=0.15) - back be             \n",
      "           make sure - (w=0.33/v=0.11) 0.04 | -0.03 (w=-0.39/v=0.07) - money               \n",
      "              be hit - (w=0.24/v=0.14) 0.03 | -0.03 (w=-0.15/v=0.17) - and notley          \n",
      "                 cut - (w=0.36/v=0.08) 0.03 | -0.02 (w=-0.22/v=0.09) - member              \n",
      "           other non - (w=0.18/v=0.16) 0.03 | -0.02 (w=-0.20/v=0.10) - just like           \n",
      "               while - (w=0.33/v=0.07) 0.02 | -0.02 (w=-0.17/v=0.11) - other               \n",
      "                 and - (w=0.29/v=0.08) 0.02 | -0.02 (w=-0.11/v=0.18) - other union         \n",
      "        union member - (w=0.15/v=0.15) 0.02 | -0.02 (w=-0.56/v=0.03) - in                  \n",
      "               their - (w=0.44/v=0.05) 0.02 | -0.02 (w=-0.14/v=0.12) - public sector       \n",
      "                 non - (w=0.24/v=0.09) 0.02 | -0.02 (w=-0.08/v=0.19) - sure her            \n",
      "              sector - (w=0.20/v=0.10) 0.02 | -0.02 (w=-0.09/v=0.17) - hit all             \n",
      "                  bc - (w=0.20/v=0.10) 0.02 | -0.01 (w=-0.19/v=0.07) - back                \n",
      "           while cut - (w=0.11/v=0.17) 0.02 | -0.01 (w=-0.10/v=0.11) - get their           \n",
      "                like - (w=0.34/v=0.05) 0.02 | -0.01 (w=-0.14/v=0.07) - public              \n",
      "          member get - (w=0.09/v=0.18) 0.02 | -0.01 (w=-0.13/v=0.05) - make                \n",
      "                  be - (w=0.76/v=0.02) 0.02 | -0.01 (w=-0.04/v=0.16) - non union           \n",
      "                just - (w=0.24/v=0.05) 0.01 | -0.00 (w=-0.02/v=0.21) - albertans just      \n",
      "                 all - (w=0.19/v=0.05) 0.01 | -0.00 (w=-0.02/v=0.19) - and horgan          \n",
      "               in bc - (w=0.07/v=0.12) 0.01 | -0.00 (w=-0.02/v=0.14) - albertans           \n",
      "               leave - (w=0.05/v=0.07) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 get - (w=0.03/v=0.05) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "          sector and - (w=0.01/v=0.15) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "       horgan weaver - (w=0.00/v=0.21) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : ['crook']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "I think Trump have unwittingly advance the march toward a single payer here . From your lip to God have ear and through his Spirit to your heart . But damn it how long Lord . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 1.04 ----\n",
      "                          sum toxic : 1.77  |  -0.73 : sum non-toxic                      \n",
      "\n",
      "                damn - (w=8.75/v=0.11) 0.99 | -0.07 (w=-0.47/v=0.16) - the march           \n",
      "             damn it - (w=1.29/v=0.18) 0.23 | -0.06 (w=-0.36/v=0.15) - and through         \n",
      "                your - (w=1.35/v=0.10) 0.14 | -0.05 (w=-0.32/v=0.15) - your heart          \n",
      "           heart but - (w=0.37/v=0.18) 0.06 | -0.04 (w=-0.31/v=0.14) - think trump         \n",
      "               trump - (w=0.90/v=0.06) 0.05 | -0.04 (w=-0.58/v=0.07) - long                \n",
      "                 his - (w=0.88/v=0.06) 0.05 | -0.04 (w=-0.25/v=0.17) - have ear            \n",
      "                 ear - (w=0.31/v=0.13) 0.04 | -0.03 (w=-0.27/v=0.12) - how long            \n",
      "                 god - (w=0.39/v=0.09) 0.04 | -0.03 (w=-0.58/v=0.06) - think               \n",
      "          trump have - (w=0.31/v=0.09) 0.03 | -0.03 (w=-0.31/v=0.11) - heart               \n",
      "              spirit - (w=0.22/v=0.12) 0.03 | -0.03 (w=-0.40/v=0.08) - through             \n",
      "            but damn - (w=0.12/v=0.20) 0.02 | -0.03 (w=-0.19/v=0.16) - ear and             \n",
      "              it how - (w=0.14/v=0.15) 0.02 | -0.03 (w=-0.17/v=0.17) - your lip            \n",
      "         through his - (w=0.12/v=0.15) 0.02 | -0.03 (w=-0.23/v=0.11) - advance             \n",
      "           from your - (w=0.13/v=0.12) 0.02 | -0.02 (w=-0.19/v=0.13) - lord                \n",
      "            god have - (w=0.07/v=0.13) 0.01 | -0.02 (w=-0.21/v=0.11) - payer               \n",
      "                 and - (w=0.29/v=0.03) 0.01 | -0.02 (w=-0.11/v=0.17) - unwittingly         \n",
      "                 how - (w=0.12/v=0.06) 0.01 | -0.02 (w=-0.14/v=0.13) - single payer        \n",
      "              to god - (w=0.04/v=0.15) 0.01 | -0.02 (w=-0.09/v=0.19) - lip to              \n",
      "         advance the - (w=0.00/v=0.16) 0.00 | -0.02 (w=-0.12/v=0.14) - lip                 \n",
      "              toward - (w=0.00/v=0.12) 0.00 | -0.02 (w=-0.35/v=0.05) - but                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.10/v=0.10) - to your             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.20/v=0.05) - from                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.05/v=0.21) - have unwittingly    \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.15/v=0.06) - have                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.06/v=0.12) - march               \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.04/v=0.15) - here from           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.14/v=0.04) - it                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.10/v=0.05) - to                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.02/v=0.20) - toward single       \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.04/v=0.07) - here                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.18) - spirit to           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.02) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.20) - his spirit          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.10) - single              \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.22) - payer here          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.20) - march toward        \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: N-Tox. Ass. Stopword in Bigrams\n",
      "Words    : ['the march, and through']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Immigration reform be long overdue . Keep the trash out . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.82 ----\n",
      "                          sum toxic : 1.37  |  -0.54 : sum non-toxic                      \n",
      "\n",
      "               trash - (w=5.32/v=0.24) 1.27 | -0.10 (w=-0.44/v=0.23) - reform              \n",
      "                keep - (w=0.31/v=0.15) 0.05 | -0.08 (w=-0.58/v=0.15) - long                \n",
      "                  be - (w=0.76/v=0.05) 0.04 | -0.08 (w=-0.25/v=0.31) - the trash           \n",
      "         immigration - (w=0.05/v=0.21) 0.01 | -0.07 (w=-0.15/v=0.44) - trash out           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.06 (w=-0.20/v=0.32) - reform be           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.05 (w=-0.23/v=0.22) - keep the            \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.03 (w=-0.13/v=0.25) - be long             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.02 (w=-0.07/v=0.33) - immigration reform  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.02 (w=-0.08/v=0.29) - overdue             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.02/v=0.30) - long overdue        \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.05/v=0.11) - out                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.11/v=0.05) - the                 \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: \n",
      "Words    : ['keep out, reform, long, the trash']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "More Donald Trumps and in Canada who know well about Intelligence Spying I mean than the professional do . Your credibility suck guy . Take a deep breath . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.55 ----\n",
      "                          sum toxic : 1.21  |  -0.66 : sum non-toxic                      \n",
      "\n",
      "                suck - (w=6.13/v=0.14) 0.83 | -0.11 (w=-0.53/v=0.21) - well about          \n",
      "                your - (w=1.35/v=0.06) 0.09 | -0.08 (w=-0.62/v=0.13) - deep                \n",
      "                more - (w=0.51/v=0.12) 0.06 | -0.06 (w=-0.41/v=0.14) - who know            \n",
      "                 guy - (w=0.32/v=0.10) 0.03 | -0.05 (w=-0.36/v=0.15) - credibility         \n",
      "          canada who - (w=0.15/v=0.20) 0.03 | -0.05 (w=-0.22/v=0.24) - mean than           \n",
      "              trumps - (w=0.19/v=0.15) 0.03 | -0.04 (w=-0.19/v=0.23) - guy take            \n",
      "     professional do - (w=0.10/v=0.25) 0.03 | -0.04 (w=-0.18/v=0.19) - the professional    \n",
      "        intelligence - (w=0.16/v=0.14) 0.02 | -0.03 (w=-0.22/v=0.13) - professional        \n",
      "           know well - (w=0.13/v=0.16) 0.02 | -0.03 (w=-0.57/v=0.05) - do                  \n",
      "           take deep - (w=0.10/v=0.20) 0.02 | -0.02 (w=-0.11/v=0.21) - your credibility    \n",
      "            than the - (w=0.12/v=0.12) 0.01 | -0.02 (w=-0.56/v=0.04) - in                  \n",
      "             do your - (w=0.08/v=0.16) 0.01 | -0.02 (w=-0.12/v=0.16) - breath              \n",
      "                 and - (w=0.29/v=0.03) 0.01 | -0.02 (w=-0.14/v=0.12) - in canada           \n",
      "                than - (w=0.13/v=0.07) 0.01 | -0.02 (w=-0.14/v=0.12) - donald              \n",
      "                know - (w=0.08/v=0.07) 0.01 | -0.02 (w=-0.06/v=0.24) - trumps and          \n",
      "                mean - (w=0.02/v=0.09) 0.00 | -0.01 (w=-0.19/v=0.06) - about               \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.12/v=0.08) - well                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.04/v=0.20) - deep breath         \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.05/v=0.13) - and in              \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.08/v=0.08) - take                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.02/v=0.25) - about intelligence  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.05/v=0.09) - canada              \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.03) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.24) - spying              \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.06) - who                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.23) - donald trumps       \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: \n",
      "Words    : ['well about, who know']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Bullet to the head . End of story . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 1.05 ----\n",
      "                          sum toxic : 1.39  |  -0.34 : sum non-toxic                      \n",
      "\n",
      "              bullet - (w=1.36/v=0.32) 0.44 | -0.18 (w=-0.33/v=0.53) - head end            \n",
      "           bullet to - (w=0.70/v=0.45) 0.31 | -0.15 (w=-0.77/v=0.20) - story               \n",
      "                head - (w=1.02/v=0.21) 0.22 | -0.01 (w=-0.10/v=0.06) - to                  \n",
      "            of story - (w=0.58/v=0.34) 0.20 | -0.01 (w=-0.11/v=0.06) - the                 \n",
      "              end of - (w=0.69/v=0.25) 0.18 | -0.00 (w=-0.00/v=0.07) - of                  \n",
      "            the head - (w=0.11/v=0.29) 0.03 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 end - (w=0.08/v=0.19) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "              to the - (w=0.03/v=0.14) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: \n",
      "Words    : ['bullet head, story']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "That kind intrusive abusive behavior be simply hand down Creepy cop all around . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.76 ----\n",
      "                          sum toxic : 0.91  |  -0.15 : sum non-toxic                      \n",
      "\n",
      "             cop all - (w=0.59/v=0.35) 0.21 | -0.05 (w=-0.35/v=0.14) - around              \n",
      "             abusive - (w=0.83/v=0.24) 0.20 | -0.03 (w=-0.18/v=0.18) - behavior            \n",
      "              creepy - (w=0.60/v=0.25) 0.15 | -0.03 (w=-0.17/v=0.19) - be simply           \n",
      "          all around - (w=0.36/v=0.24) 0.09 | -0.02 (w=-0.07/v=0.28) - intrusive           \n",
      "         behavior be - (w=0.21/v=0.25) 0.05 | -0.01 (w=-0.03/v=0.33) - simply hand         \n",
      "                 cop - (w=0.22/v=0.19) 0.04 | -0.01 (w=-0.02/v=0.26) - hand down           \n",
      "              simply - (w=0.23/v=0.15) 0.03 | -0.00 (w=-0.06/v=0.05) - that                \n",
      "                  be - (w=0.76/v=0.04) 0.03 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                hand - (w=0.20/v=0.15) 0.03 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                down - (w=0.22/v=0.12) 0.03 | 0.00 (w=0.00/v=0.00) -                     \n",
      "    abusive behavior - (w=0.07/v=0.34) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                 all - (w=0.19/v=0.08) 0.02 | 0.00 (w=0.00/v=0.00) -                     \n",
      "                kind - (w=0.09/v=0.15) 0.01 | 0.00 (w=0.00/v=0.00) -                     \n",
      "           that kind - (w=0.02/v=0.22) 0.00 | 0.00 (w=0.00/v=0.00) -                     \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "I never say it never happen . You lie . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.27 ----\n",
      "                          sum toxic : 0.48  |  -0.21 : sum non-toxic                      \n",
      "\n",
      "                 lie - (w=1.20/v=0.22) 0.26 | -0.11 (w=-0.54/v=0.20) - happen              \n",
      "        never happen - (w=0.21/v=0.35) 0.07 | -0.05 (w=-0.14/v=0.36) - never               \n",
      "                 you - (w=0.65/v=0.10) 0.06 | -0.02 (w=-0.06/v=0.35) - never say           \n",
      "             you lie - (w=0.11/v=0.38) 0.04 | -0.01 (w=-0.14/v=0.10) - it                  \n",
      "            it never - (w=0.10/v=0.35) 0.04 | -0.01 (w=-0.05/v=0.27) - say it              \n",
      "          happen you - (w=0.02/v=0.41) 0.01 | -0.01 (w=-0.06/v=0.15) - say                 \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "a decision that represent a optimistic moment in a dark time a lawyer for the plaintiff say . How ironic that this dimwitted lawyer would engage in such silly conflation . The only reason I vote for Trump a man I consider obnoxious and woefully uninformed be because he promise to rein in our rogue federal judiciary . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 1.05 ----\n",
      "                          sum toxic : 1.78  |  -0.73 : sum non-toxic                      \n",
      "\n",
      "               silly - (w=7.52/v=0.09) 0.71 | -0.06 (w=-0.64/v=0.09) - be because          \n",
      "           dimwitted - (w=1.08/v=0.15) 0.16 | -0.06 (w=-0.48/v=0.12) - ironic that         \n",
      "           obnoxious - (w=1.26/v=0.12) 0.15 | -0.05 (w=-0.31/v=0.15) - such silly          \n",
      "                 man - (w=1.89/v=0.07) 0.13 | -0.04 (w=-0.56/v=0.08) - in                  \n",
      "         time lawyer - (w=0.28/v=0.17) 0.05 | -0.04 (w=-0.42/v=0.10) - engage in           \n",
      "       obnoxious and - (w=0.30/v=0.15) 0.05 | -0.04 (w=-0.35/v=0.10) - in such             \n",
      "               trump - (w=0.90/v=0.05) 0.04 | -0.03 (w=-0.21/v=0.17) - uninformed be       \n",
      "         only reason - (w=0.39/v=0.11) 0.04 | -0.03 (w=-0.32/v=0.11) - ironic              \n",
      "          uninformed - (w=0.39/v=0.11) 0.04 | -0.03 (w=-0.41/v=0.07) - decision            \n",
      "            vote for - (w=0.51/v=0.07) 0.04 | -0.03 (w=-0.34/v=0.09) - because he          \n",
      "                such - (w=0.53/v=0.06) 0.03 | -0.03 (w=-0.19/v=0.14) - how ironic          \n",
      "             rein in - (w=0.22/v=0.13) 0.03 | -0.03 (w=-0.39/v=0.07) - reason              \n",
      "               rogue - (w=0.22/v=0.12) 0.03 | -0.02 (w=-0.16/v=0.15) - dark time           \n",
      "                rein - (w=0.19/v=0.12) 0.02 | -0.02 (w=-0.20/v=0.12) - optimistic          \n",
      "                this - (w=0.69/v=0.03) 0.02 | -0.02 (w=-0.26/v=0.08) - that this           \n",
      "                  he - (w=0.49/v=0.04) 0.02 | -0.02 (w=-0.26/v=0.07) - consider            \n",
      "              engage - (w=0.22/v=0.09) 0.02 | -0.02 (w=-0.11/v=0.14) - to rein             \n",
      "           trump man - (w=0.13/v=0.15) 0.02 | -0.01 (w=-0.17/v=0.08) - in our              \n",
      "                only - (w=0.39/v=0.05) 0.02 | -0.01 (w=-0.15/v=0.09) - for trump           \n",
      "   federal judiciary - (w=0.12/v=0.15) 0.02 | -0.01 (w=-0.21/v=0.06) - for                 \n",
      "        lawyer would - (w=0.13/v=0.15) 0.02 | -0.01 (w=-0.14/v=0.08) - promise             \n",
      "        man consider - (w=0.11/v=0.17) 0.02 | -0.01 (w=-0.07/v=0.15) - reason vote         \n",
      "                dark - (w=0.17/v=0.10) 0.02 | -0.01 (w=-0.09/v=0.13) - woefully            \n",
      "                  be - (w=0.76/v=0.02) 0.01 | -0.01 (w=-0.23/v=0.05) - time                \n",
      "       the plaintiff - (w=0.08/v=0.13) 0.01 | -0.01 (w=-0.13/v=0.08) - represent           \n",
      "          lawyer for - (w=0.08/v=0.14) 0.01 | -0.01 (w=-0.10/v=0.10) - promise to          \n",
      "              lawyer - (w=0.06/v=0.17) 0.01 | -0.01 (w=-0.15/v=0.06) - vote                \n",
      "              moment - (w=0.09/v=0.09) 0.01 | -0.01 (w=-0.07/v=0.13) - moment in           \n",
      "             because - (w=0.14/v=0.05) 0.01 | -0.01 (w=-0.19/v=0.04) - would               \n",
      "                 and - (w=0.29/v=0.02) 0.01 | -0.01 (w=-0.09/v=0.07) - federal             \n",
      "           plaintiff - (w=0.04/v=0.12) 0.01 | -0.01 (w=-0.12/v=0.05) - our                 \n",
      "                 how - (w=0.12/v=0.05) 0.01 | -0.00 (w=-0.07/v=0.07) - the only            \n",
      "      that represent - (w=0.02/v=0.13) 0.00 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "          conflation - (w=0.01/v=0.15) 0.00 | -0.00 (w=-0.06/v=0.05) - that                \n",
      "             in dark - (w=0.01/v=0.14) 0.00 | -0.00 (w=-0.06/v=0.05) - say                 \n",
      "       decision that - (w=0.01/v=0.12) 0.00 | -0.00 (w=-0.10/v=0.02) - to                  \n",
      "           judiciary - (w=0.00/v=0.12) 0.00 | -0.00 (w=-0.01/v=0.12) - say how             \n",
      "        would engage - (w=0.00/v=0.16) 0.00 | -0.00 (w=-0.02/v=0.05) - for the             \n",
      " woefully uninformed - (w=0.00/v=0.17) 0.00 | -0.00 (w=-0.01/v=0.12) - he promise          \n",
      "       rogue federal - (w=0.00/v=0.18) 0.00 | -0.00 (w=-0.00/v=0.17) - and woefully        \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.17) - our rogue           \n",
      "\n",
      "\n",
      "Category : N-Tox. Ass. Neutral words\n",
      "Category2: N-Tox. Ass. Stopword in Bigrams\n",
      "Words    : ['be because, such silly']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Even the slow voter will come to term with the fact that beyond the nice hair and sock be a politician behave good like a politician phoney mislead and when off script inept . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.58 ----\n",
      "                          sum toxic : 1.18  |  -0.60 : sum non-toxic                      \n",
      "\n",
      "               inept - (w=3.74/v=0.15) 0.57 | -0.08 (w=-0.47/v=0.17) - be politician       \n",
      "          politician - (w=0.52/v=0.20) 0.10 | -0.06 (w=-0.43/v=0.14) - behave              \n",
      "           nice hair - (w=0.37/v=0.18) 0.07 | -0.05 (w=-0.36/v=0.13) - hair                \n",
      "         mislead and - (w=0.31/v=0.18) 0.06 | -0.05 (w=-0.27/v=0.17) - hair and            \n",
      "                slow - (w=0.36/v=0.12) 0.04 | -0.04 (w=-0.21/v=0.21) - when off            \n",
      "          voter will - (w=0.26/v=0.16) 0.04 | -0.04 (w=-0.26/v=0.14) - beyond the          \n",
      "         behave good - (w=0.17/v=0.21) 0.04 | -0.03 (w=-0.17/v=0.20) - sock be             \n",
      "                 off - (w=0.39/v=0.08) 0.03 | -0.03 (w=-0.35/v=0.10) - nice                \n",
      "            and when - (w=0.24/v=0.12) 0.03 | -0.03 (w=-0.13/v=0.20) - like politician     \n",
      "           will come - (w=0.19/v=0.13) 0.02 | -0.03 (w=-0.14/v=0.18) - phoney              \n",
      "            and sock - (w=0.12/v=0.20) 0.02 | -0.03 (w=-0.44/v=0.06) - good                \n",
      "                like - (w=0.34/v=0.06) 0.02 | -0.03 (w=-0.27/v=0.09) - term                \n",
      "                  be - (w=0.76/v=0.02) 0.02 | -0.02 (w=-0.34/v=0.06) - when                \n",
      "                 and - (w=0.29/v=0.06) 0.02 | -0.02 (w=-0.12/v=0.16) - the nice            \n",
      "           term with - (w=0.10/v=0.17) 0.02 | -0.01 (w=-0.08/v=0.18) - to term             \n",
      "             mislead - (w=0.11/v=0.13) 0.01 | -0.01 (w=-0.15/v=0.08) - fact                \n",
      "          off script - (w=0.06/v=0.21) 0.01 | -0.01 (w=-0.15/v=0.07) - with the            \n",
      "           good like - (w=0.07/v=0.17) 0.01 | -0.01 (w=-0.07/v=0.15) - script              \n",
      "           fact that - (w=0.10/v=0.10) 0.01 | -0.01 (w=-0.11/v=0.07) - the                 \n",
      "            the slow - (w=0.04/v=0.17) 0.01 | -0.01 (w=-0.04/v=0.15) - sock                \n",
      "            the fact - (w=0.06/v=0.09) 0.01 | -0.01 (w=-0.06/v=0.10) - voter               \n",
      "                with - (w=0.12/v=0.05) 0.01 | -0.00 (w=-0.07/v=0.07) - even                \n",
      "              beyond - (w=0.05/v=0.11) 0.01 | -0.00 (w=-0.10/v=0.03) - to                  \n",
      "             come to - (w=0.04/v=0.10) 0.00 | -0.00 (w=-0.02/v=0.12) - even the            \n",
      "                come - (w=0.03/v=0.07) 0.00 | -0.00 (w=-0.06/v=0.03) - that                \n",
      "         that beyond - (w=0.00/v=0.23) 0.00 | -0.00 (w=-0.02/v=0.05) - will                \n",
      "\n",
      "\n",
      "Category : No tox. Words\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Nor the prior to that . -PRON- have a vicious cycle of mediocrity . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.23 ----\n",
      "                          sum toxic : 0.63  |  -0.40 : sum non-toxic                      \n",
      "\n",
      "          mediocrity - (w=0.86/v=0.29) 0.25 | -0.10 (w=-0.46/v=0.21) - prior               \n",
      "             vicious - (w=0.53/v=0.27) 0.14 | -0.07 (w=-0.25/v=0.29) - cycle of            \n",
      "       of mediocrity - (w=0.27/v=0.34) 0.09 | -0.06 (w=-0.21/v=0.29) - the prior           \n",
      "                pron - (w=0.94/v=0.08) 0.07 | -0.06 (w=-0.27/v=0.22) - cycle               \n",
      "           that pron - (w=0.26/v=0.18) 0.05 | -0.05 (w=-0.14/v=0.34) - have vicious        \n",
      "            prior to - (w=0.09/v=0.22) 0.02 | -0.02 (w=-0.12/v=0.18) - nor                 \n",
      "             to that - (w=0.06/v=0.18) 0.01 | -0.01 (w=-0.03/v=0.33) - vicious cycle       \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.08/v=0.10) - pron have           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.15/v=0.05) - have                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.10/v=0.05) - to                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.11/v=0.04) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.26) - nor the             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.06/v=0.06) - that                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.05) - of                  \n",
      "\n",
      "\n",
      "Category : disagree\n",
      "Category2: \n",
      "Words    : \n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n",
      "You can not erase history . Why doe the medium give coverage to the much foolish idea . Check out study by Princeton a to the criterium for remove name statue etc . \n",
      "True label: 1\n",
      "\n",
      "-                                   ---- Result: 0.86 ----\n",
      "                          sum toxic : 1.43  |  -0.57 : sum non-toxic                      \n",
      "\n",
      "             foolish - (w=7.23/v=0.14) 0.99 | -0.08 (w=-0.60/v=0.13) - check out           \n",
      "         history why - (w=0.46/v=0.20) 0.09 | -0.06 (w=-0.41/v=0.14) - statue              \n",
      "       erase history - (w=0.38/v=0.19) 0.07 | -0.04 (w=-0.41/v=0.11) - the medium          \n",
      "        much foolish - (w=0.34/v=0.20) 0.07 | -0.04 (w=-0.28/v=0.15) - erase               \n",
      "             can not - (w=0.77/v=0.07) 0.05 | -0.04 (w=-0.21/v=0.19) - not erase           \n",
      "              remove - (w=0.37/v=0.11) 0.04 | -0.03 (w=-0.12/v=0.22) - idea check          \n",
      "            coverage - (w=0.24/v=0.12) 0.03 | -0.03 (w=-0.28/v=0.09) - history             \n",
      "                 you - (w=0.65/v=0.04) 0.03 | -0.02 (w=-0.71/v=0.03) - not                 \n",
      "                 etc - (w=0.26/v=0.09) 0.02 | -0.02 (w=-0.46/v=0.05) - can                 \n",
      "            the much - (w=0.10/v=0.09) 0.01 | -0.02 (w=-0.11/v=0.19) - princeton           \n",
      "         medium give - (w=0.04/v=0.19) 0.01 | -0.02 (w=-0.22/v=0.09) - idea                \n",
      "       the criterium - (w=0.04/v=0.17) 0.01 | -0.02 (w=-0.35/v=0.05) - by                  \n",
      "              medium - (w=0.07/v=0.09) 0.01 | -0.02 (w=-0.18/v=0.10) - check               \n",
      "              to the - (w=0.03/v=0.12) 0.00 | -0.02 (w=-0.19/v=0.09) - name                \n",
      "             doe the - (w=0.03/v=0.12) 0.00 | -0.02 (w=-0.23/v=0.07) - why                 \n",
      "               study - (w=0.02/v=0.11) 0.00 | -0.02 (w=-0.11/v=0.13) - why doe             \n",
      "            study by - (w=0.00/v=0.18) 0.00 | -0.01 (w=-0.08/v=0.18) - coverage to         \n",
      "        by princeton - (w=0.00/v=0.23) 0.00 | -0.01 (w=-0.16/v=0.07) - doe                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.21/v=0.04) - for                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.10/v=0.08) - you can             \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.11/v=0.07) - the                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.04/v=0.15) - criterium           \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.10/v=0.06) - to                  \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.01 (w=-0.02/v=0.23) - foolish idea        \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.18) - criterium for       \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.05/v=0.06) - out                 \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.23) - give coverage       \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.03/v=0.05) - much                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.01/v=0.07) - give                \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.20) - for remove          \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.22) - remove name         \n",
      "                     - (w=0.00/v=0.00) 0.00 | -0.00 (w=-0.00/v=0.23) - statue etc          \n",
      "\n",
      "\n",
      "Category : Lack of tox. Words\n",
      "Category2: N-Tox. Ass to tox. Words\n",
      "Words    : ['foolish idea']\n",
      "\n",
      "------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print a models weights, featrue values and feature names for list of samples\n",
    "def print_feature_weights_for_sample(model, featurizer, sample_comments, sample_labels):\n",
    "    model_weights = model.coef_\n",
    "    vectorized_samples = featurizer.transform(sample_comments)\n",
    "    idx_to_feat_name_vocab = {v: k for k, v in featurizer.vocabulary_.items()} \n",
    "    \n",
    "    manual_insp_false_negatives = pd.read_csv(\"inspection/false_negatives.csv\")\n",
    "    annotated_comments = list(manual_insp_false_negatives['comment_text'])\n",
    "    \n",
    "    for i, row in enumerate(vectorized_samples):\n",
    "        if(sample_comments[i] in annotated_comments):\n",
    "            cat1 = list(manual_insp_false_negatives[manual_insp_false_negatives['comment_text'] == sample_comments[i]]['category'])[0]\n",
    "            l = list(manual_insp_false_negatives[manual_insp_false_negatives['comment_text'] == sample_comments[i]]['category2'])\n",
    "            cat2 = l[0] if str(l[0]) != \"nan\" else \"\"\n",
    "            cats = ['Lack of tox. Words', 'disagree', 'N-Tox. Ass. Neutral words', 'No tox. Words']\n",
    "            if (cat1 in cats or cat2 in cats):\n",
    "                sumi = 0\n",
    "                features_pos = {}\n",
    "                features_neg = {}\n",
    "                print(sample_comments[i], \"\\n\" + \"True label:\", sample_labels[i])\n",
    "                #print('\\n{:20s} {:5s}  | {:5s} {:>15s}'.format(\"Feature\", \"Weight\", \"Value\", \"Result\"))\n",
    "\n",
    "                for idx in row.nonzero()[1]:\n",
    "                    weight = model_weights[0][idx]\n",
    "                    #print('{:>20s} - {: 3.2f} | {: 3.2f}  =  '\\\n",
    "                    #      .format(idx_to_feat_name_vocab[idx], weight, row.getcol(idx).toarray()[0][0]), (weight * row.getcol(idx).toarray()[0][0]))\n",
    "                    if (weight * row.getcol(idx).toarray()[0][0] >= 0):\n",
    "                        features_pos[idx_to_feat_name_vocab[idx]] = (weight * row.getcol(idx).toarray()[0][0], weight, row.getcol(idx).toarray()[0][0])\n",
    "                    else:\n",
    "                        features_neg[idx_to_feat_name_vocab[idx]] = (weight * row.getcol(idx).toarray()[0][0], weight, row.getcol(idx).toarray()[0][0])\n",
    "                    sumi += (weight * row.getcol(idx).toarray()[0][0])\n",
    "                print(\"\\n-{:>35s}---- Result: {:2.2f} ----\".format(\"\", sumi))\n",
    "\n",
    "                features_pos = list({k: v for k, v in sorted(features_pos.items(), key=lambda item: item[1])}.items())\n",
    "                features_neg = list({k: v for k, v in sorted(features_neg.items(), key=lambda item: item[1])}.items())\n",
    "\n",
    "                print(\"{:>35s} : {:3.2f}  |  {:3.2f} : {:35s}\\n\".format(\"sum toxic\", sum([x[1][0] for x in features_pos]), \\\n",
    "                                                                        sum([x[1][0] for x in features_neg]), \"sum non-toxic\"))\n",
    "                for j in range(0, max(len(features_pos), len(features_neg))):\n",
    "                    print(\"{:>20s} - (w={:3.2f}/v={:3.2f}) {:3.2f} | {:3.2f} (w={:3.2f}/v={:3.2f}) - {:20s}\".format(\\\n",
    "                         (features_pos[len(features_pos) - 1 -j][0] if j <len(features_pos) else \"\"),\\\n",
    "                         (features_pos[len(features_pos) - 1 - j][1][1] if j <len(features_pos) else 0),\\\n",
    "                         (features_pos[len(features_pos) - 1 - j][1][2] if j <len(features_pos) else 0),\\\n",
    "                         (features_pos[len(features_pos) - 1 - j][1][0] if j <len(features_pos) else 0),\\\n",
    "                         (features_neg[j][1][0] if j <len(features_neg) else 0),\\\n",
    "                         (features_neg[j][1][1] if j <len(features_neg) else 0),\\\n",
    "                         (features_neg[j][1][2] if j <len(features_neg) else 0),\\\n",
    "                         (features_neg[j][0] if j <len(features_neg) else \"\")))\n",
    "                print(\"\\n\")\n",
    "                print(\"Category :\", cat1)\n",
    "\n",
    "                print(\"Category2:\",cat2)\n",
    "                l1 = list(manual_insp_false_negatives[manual_insp_false_negatives['comment_text'] == sample_comments[i]]['append.'])\n",
    "                print(\"Words    :\", l1 if str(l1[0]) != \"nan\" else \"\")\n",
    "\n",
    "                print(\"\\n------------------------------------------------------------------\\n\")\n",
    "\n",
    "featurizer, train_events, train_labels, valid_events, valid_labels, predicted_labels, model = res \n",
    "\n",
    "incorrectly_classified = pd.read_csv(\"examples/incorrect.csv\")\n",
    "false_negatives = incorrectly_classified.loc[incorrectly_classified['target'] == 1]\n",
    "false_positives = incorrectly_classified.loc[incorrectly_classified['target'] == 0]\n",
    "#lstm_vs_svm = pd.read_csv(\"examples/lstm_vs_svm_valid.csv\")\n",
    "#false_negatives = lstm_vs_svm.loc[(lstm_vs_svm['lstm_result'] == 1) & (lstm_vs_svm['target'] == 1) & (lstm_vs_svm['svm_result'] == 0)]\n",
    "#print(len(false_negatives))\n",
    "\n",
    "print('b = ',model.intercept_)\n",
    "print_feature_weights_for_sample(model, featurizer, list(false_negatives['comment_text']) , list(false_negatives['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_featurizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-175788a45458>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Printing featurized version of a comment to check if everything went right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcustom_featurizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_sample_with_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_tfidf_custom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_featurizer' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Precision 97.28552501830016 Recall 96.78199796580384 Recall 97.03310826711076 AUC 82.80464355703002\n",
      "1 Precision 64.94689917398715 Recall 68.82728914825623 Recall 66.83081489476524 AUC 82.80464355703002\n"
     ]
    }
   ],
   "source": [
    "#A cell for trying stuff out\n",
    "\n",
    "#custom_featurizer.print_sample_with_feature_names(train_tfidf_custom, 1)\n",
    "#featurizer, train_events, train_labels, valid_events, valid_labels, predicted_labels, model = res\n",
    "#te = tfidf_vectorizer.transform(['Wow . be a hate fill monster .'])\n",
    "#te = tfidf_vectorizer.transform([\"Holy crap . You be amazing . Such fun . \"])\n",
    "#model.predict(te)\n",
    "#print_feature_weights_for_sample(model, featurizer, [\"He is an idiot !\"], [1])\n",
    "\n",
    "merged = pd.read_csv(\"data/merged.csv\")\n",
    "#roc_auc_score, precision_recall_fscore_support\n",
    "stats = precision_recall_fscore_support(merged['target'],merged['result'])\n",
    "auc = roc_auc_score(merged['target'],merged['result'])\n",
    "print(\"0 Precision\", stats[0][0] * 100, \"Recall\", stats[1][0] * 100, \"Fscore\", stats[2][0] * 100, \"AUC\", auc * 100)\n",
    "print(\"1 Precision\", stats[0][1] * 100, \"Recall\", stats[1][1] * 100, \"Fscore\", stats[2][1] * 100, \"AUC\", auc * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for getting most toxic features\n",
    "featurizer, train_events, train_labels, valid_events, valid_labels, predicted_labels, model = res \n",
    "model_weights = model.coef_.copy()\n",
    "\n",
    "max_idxs = np.argpartition(model_weights[0], -100)[-100:]\n",
    "\n",
    "idx_to_feat_name_vocab = {v: k for k, v in tfidf_vectorizer.vocabulary_.items()} \n",
    "\n",
    "for idx in max_idxs:\n",
    "    print(idx_to_feat_name_vocab[idx])\n",
    "#print(np.array(model_weights).argsort()[-30:][::-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
